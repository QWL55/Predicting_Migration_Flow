{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QWL55/Predicting_Migration_Flow/blob/main/CS224W_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Final Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCK7krJdp4o8"
      },
      "source": [
        "# Setup\n",
        "First let us check which version of PyTorch you are running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vkP8pA1qBE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221e552b-1b7f-4c7d-8eff-8a307cf9769a"
      },
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.10/dist-packages (2.1.2+pt25cu121)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.10/dist-packages (0.6.18+pt25cu121)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 1) GNN: Link Regression Task\n",
        "\n",
        "In this section we will build our baseline graph neural network using PyTorch Geometric. Then we will apply it to the task of predicting the volume of migration flow (link regression).\n",
        "\n",
        "Specifically, we will use GCN as the foundation for the graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CcOUEoInjD"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# The PyG built-in GCNConv\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "FT_w3_lVcxdS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L68uxydJVqUx",
        "outputId": "58e92d45-4859-4f25-8543-7dccc55638ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the path to your project folder\n",
        "os.chdir('/content/drive/MyDrive/Stanford SOC/CS224W/final_projects')"
      ],
      "metadata": {
        "id": "l9GJF29jV75D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoMTUJkjdXDz",
        "outputId": "516a4f97-ea58-4853-e450-3fdc2e56a804"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CS224W_Colab_2.ipynb',\n",
              " 'dataset',\n",
              " 'county_flow.csv',\n",
              " 'county_node_info.csv',\n",
              " 'CS224W_Final_Project.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "def load_process_data(feat_type):\n",
        "    # Load the datasets\n",
        "    county_flow_df = pd.read_csv('county_flow.csv', dtype={\"fips_orig\": str, \"fips_dest\": str})\n",
        "    county_node_df = pd.read_csv('county_node_info.csv', dtype={\"GEOID\": str})\n",
        "\n",
        "    # Step 1: Create a mapping from GEOID to index and\n",
        "    # map fips_orig and fips_dest in county_flow_df to indices\n",
        "    geo_to_index = {geo_id: idx for idx, geo_id in enumerate(county_node_df['GEOID'])}\n",
        "\n",
        "    county_flow_df['src'] = county_flow_df['fips_orig'].map(geo_to_index)\n",
        "    county_flow_df['dst'] = county_flow_df['fips_dest'].map(geo_to_index)\n",
        "\n",
        "    # Drop any rows with missing mappings (i.e., if a fips code doesn't exist in county_node_df)\n",
        "    county_flow_df = county_flow_df.dropna(subset=['src', 'dst']).astype({'src': int, 'dst': int})\n",
        "\n",
        "    # Step 2: Extract the edge list and label\n",
        "    edge_index_df = county_flow_df[['src', 'dst']]\n",
        "    edge_index = torch.tensor(edge_index_df.values.T, dtype=torch.long)\n",
        "\n",
        "    edge_labels = county_flow_df['flow'].values\n",
        "    edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
        "\n",
        "    # Step 3: Create two versions of county_node_features\n",
        "    if feat_type == 'full':\n",
        "        # includes all columns except GEOID\n",
        "        columns_to_drop = ['GEOID']\n",
        "    elif feat_type == 'simple':\n",
        "        # excludes columns with \"feature\" in their names\n",
        "        columns_to_drop = ['GEOID'] + [col for col in county_node_df.columns if 'feature' in col.lower()]\n",
        "    elif feat_type == 'pdfm':\n",
        "        # include only pdfm features\n",
        "        columns_to_drop = ['GEOID'] + [col for col in county_node_df.columns if 'feature' not in col.lower()]\n",
        "\n",
        "    # select relevant features\n",
        "    county_node_features = county_node_df.drop(columns=columns_to_drop, errors='ignore').values\n",
        "    county_node_features = torch.tensor(county_node_features, dtype=torch.float)\n",
        "\n",
        "    # Create PyG Data object\n",
        "    data = Data(x=county_node_features, edge_index=edge_index, y=edge_labels,\n",
        "                edge_label=edge_labels)\n",
        "    data.num_node_features = county_node_features.shape[1]\n",
        "    data.num_classes = 1\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "NojfEz27VVQa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_full = load_process_data('full')\n",
        "data_simple = load_process_data('simple')\n",
        "data_pdfm = load_process_data('pdfm')\n",
        "\n",
        "print(\"Data with full features:\")\n",
        "print(data_full)\n",
        "print(\"\\nData with simple features:\")\n",
        "print(data_simple)\n",
        "print(\"\\nData with pdfm features:\")\n",
        "print(data_pdfm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC-KuR9_aDXT",
        "outputId": "6ea5ef0c-8c58-4f83-b3ce-5b41425b5ccd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with full features:\n",
            "Data(x=[3116, 339], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=339, num_classes=1)\n",
            "\n",
            "Data with simple features:\n",
            "Data(x=[3116, 9], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=9, num_classes=1)\n",
            "\n",
            "Data with pdfm features:\n",
            "Data(x=[3116, 330], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=330, num_classes=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splitting\n",
        "transform = T.Compose([T.ToSparseTensor(),\n",
        "                       T.RandomLinkSplit(is_undirected=False)])\n",
        "\n",
        "train_data, val_data, test_data = transform(data_full)\n",
        "train_data, val_data, test_data = transform(data_simple)\n",
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRUnj1OilrWv",
        "outputId": "b861d10c-7c7b-4dda-d177-2769f02133a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3116, 9], y=[75299], num_node_features=9, num_classes=1, adj_t=[3116, 3116, nnz=107568], edge_index=[2, 75299], edge_label=[150598], edge_label_index=[2, 150598])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.edge_label.shape\n",
        "val_data.edge_label.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_x39_DLo5lT",
        "outputId": "20667cf3-0fc3-4f34-acd7-8a6e333a3c4b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([21512])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "NKr3msRGdgQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        # times 2 because we concatenate node embedding\n",
        "        self.link_regressor = nn.Sequential(\n",
        "            nn.Linear(2 * args.heads *hidden_dim, hidden_dim),\n",
        "            nn.Dropout(args.dropout),\n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "\n",
        "        for _ in range(args.num_layers):\n",
        "            self.bns.append(torch.nn.BatchNorm1d(args.heads *hidden_dim))\n",
        "\n",
        "        self.num_layers = args.num_layers\n",
        "\n",
        "        self.emb = emb\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Reset parameters of convolutional layers\n",
        "        for conv in self.convs:\n",
        "            if hasattr(conv, 'reset_parameters'):\n",
        "                conv.reset_parameters()\n",
        "        # Reset parameters of link_regressor layers\n",
        "        for layer in self.link_regressor:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.reset_parameters()\n",
        "\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GCN':\n",
        "            return GCNConv\n",
        "        elif model_type == 'GAT':\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        out = x\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            out = self.convs[i](out, edge_index)\n",
        "            out = self.bns[i](out)\n",
        "            out = F.relu(out)\n",
        "            output = F.dropout(out, p=self.dropout,training=self.training)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return out\n",
        "\n",
        "        return self.predict_edges(out, edge_index)\n",
        "\n",
        "    def predict_edges(self, node_features, edge_index):\n",
        "        # Extract source and destination node embeddings\n",
        "        node_features_src = node_features[edge_index[0]]  # Source nodes\n",
        "        node_features_dst = node_features[edge_index[1]]  # Destination nodes\n",
        "\n",
        "        # Combine embeddings (e.g., using dot product or concatenation)\n",
        "        edge_features = torch.cat([node_features_src, node_features_dst], dim=-1)\n",
        "\n",
        "        # Predict edge values (continuous outputs)\n",
        "        edge_predictions = self.link_regressor(edge_features)\n",
        "\n",
        "        return edge_predictions\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.l1_loss(pred, label)"
      ],
      "metadata": {
        "id": "aCp_9NGOdnoQ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GraphSage\n"
      ],
      "metadata": {
        "id": "U9DtEZ2zdBcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSage(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, aggr=\"mean\", **kwargs):\n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "        self.aggr = aggr\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the (PyTorch) layers needed for the message and update functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embedding\n",
        "        #            for central node.\n",
        "        # self.lin_r is the linear transformation that you apply to aggregated\n",
        "        #            message from neighbors.\n",
        "        # Don't forget the bias as part of the linear layers!\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. Call the propagate function to conduct the message passing.\n",
        "        #    1.1 See the description of propagate above or the following link for more information:\n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
        "        #        we pass the same representation for central and neighbor nodes as x=(x, x).\n",
        "        # 2. Update our node embedding with skip connection from the previous layer.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in\n",
        "        #    torch.nn.functional)\n",
        "        out = self.propagate(edge_index, x=(x,x), size=size)\n",
        "        out = self.lin_l(x) + self.lin_r(out)\n",
        "        if self.normalize:\n",
        "            out = F.normalize(out, p=2, dim=-1)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your message function here.\n",
        "        # Hint: Look at the formulation of the mean aggregation function, focusing on\n",
        "        # what message each neighboring node passes.\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = x_j\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter:\n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce=self.aggr)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "FRy6nRB2dEWr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT\n"
      ],
      "metadata": {
        "id": "lV2etmynxHZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the layers needed for the message functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embeddings\n",
        "        # BEFORE message passing.\n",
        "        #\n",
        "        # Pay attention to dimensions of the linear layers, since we're using\n",
        "        # multi-head attention.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = nn.Linear(in_channels, heads * out_channels, bias=False)\n",
        "        ############################################################################\n",
        "\n",
        "        self.lin_r = self.lin_l\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
        "        # You have to deal with multi-head scenarios.\n",
        "        # Use nn.Parameter instead of nn.Linear\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.att_l = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        self.att_r = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
        "        # 1. First apply linear transformation to node embeddings, and split that\n",
        "        #    into multiple heads. We use the same representations for source and\n",
        "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
        "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
        "        # 3. Call propagate function to conduct the message passing.\n",
        "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
        "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Transform the output back to the shape of [N, H * C].\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        x_l, x_r = self.lin_l(x).view(-1, H, C), self.lin_r(x).view(-1, H, C)\n",
        "        alpha_l = (x_l * self.att_l).sum(dim=-1)\n",
        "        alpha_r = (x_r * self.att_r).sum(dim=-1)\n",
        "\n",
        "        out = self.propagate(edge_index, x=(x_l,x_r), alpha=(alpha_l, alpha_r), size=size)\n",
        "        out = out.view(-1, H * C)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your message function. Putting the attention in message\n",
        "        # instead of in update is a little tricky.\n",
        "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
        "        #    and apply leaky Relu.\n",
        "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use\n",
        "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
        "        # 3. Apply dropout to attention weights (alpha).\n",
        "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
        "        #    should be of shape [E, H, C].\n",
        "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
        "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
        "        # 6. size_i: corresponds to the num_nodes variable input to the torch.geometric.softmax method\n",
        "        # Our implementation is ~4-5 lines, but don't worry if you deviate from this.\n",
        "        alpha = alpha_i + alpha_j\n",
        "        out = F.leaky_relu(alpha, self.negative_slope)\n",
        "        out = torch_geometric.utils.softmax(out, index, ptr, size_i)\n",
        "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "        out = x_j * out.unsqueeze(-1)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, dim=0, dim_size=dim_size, reduce='sum')\n",
        "        ############################################################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "6tsoeQzjxJ9L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "MQ6POCTRgi1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "metadata": {
        "id": "H0nIkNBIgiIb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation"
      ],
      "metadata": {
        "id": "NvY_9LEXcUAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw3IQo05_f8k",
        "outputId": "fe6af80b-d754-41e1-aa0f-048c6e6fd622"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m174.1/179.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "from torcheval.metrics.functional import r2_score\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    transform = T.Compose([T.ToSparseTensor(),\n",
        "                       T.RandomLinkSplit(is_undirected=False)])\n",
        "    dataset = args.dataset\n",
        "    train_data, val_data, test_data = transform(dataset)\n",
        "\n",
        "    #print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
        "    #test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes,\n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    test_losses = []\n",
        "    train_r2_scores = []\n",
        "    val_r2_scores = []\n",
        "    test_r2_scores = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        model.train()\n",
        "        #for batch in loader:\n",
        "        opt.zero_grad()\n",
        "        pred = model(train_data).squeeze(-1)\n",
        "        label = train_data.y\n",
        "        #pred = pred[batch.train_mask]\n",
        "        #label = label[batch.train_mask]\n",
        "        loss = model.loss(pred, label)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_r2 = r2_score(pred, label)\n",
        "        train_r2_scores.append(train_r2.item())\n",
        "\n",
        "        val_loss, val_r2 = test(val_data, model)\n",
        "        val_losses.append(val_loss)\n",
        "        val_r2_scores.append(val_r2.item())\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}: Training Loss {round(loss.item(), 5)}, \"\n",
        "            f\"Training R2 {round(train_r2.item(), 5)}\",\n",
        "            f\"Validation Loss {round(val_loss, 5)}\",\n",
        "            f\"Validation R2 {round(val_r2.item(), 5)}\"\n",
        "        )\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "        test_loss, test_r2 = test(test_data, model)\n",
        "        test_losses.append(test_loss)\n",
        "        test_r2_scores.append(test_r2.item())\n",
        "\n",
        "    return train_losses, val_losses, test_losses, best_model, test_data\n",
        "\n",
        "\n",
        "def test(data, test_model, save_model_preds=False, model_type=None,\n",
        "         feature_type=None):\n",
        "    test_model.eval()\n",
        "\n",
        "    #correct = 0\n",
        "    # Note that Cora is only one graph!\n",
        "    with torch.no_grad():\n",
        "        # max(dim=1) returns values, indices tuple; only need indices\n",
        "        pred = test_model(data).squeeze(-1)\n",
        "        label = data.y\n",
        "        loss = test_model.loss(pred, label)\n",
        "        r2 = r2_score(pred, label)\n",
        "        #mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        #pred = pred[mask]\n",
        "        #label = label[mask]\n",
        "\n",
        "        if save_model_preds:\n",
        "            print (\"Saving Model Predictions for Model Type\", model_type)\n",
        "\n",
        "            data = {}\n",
        "            data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
        "            data['label'] = label.view(-1).cpu().detach().numpy()\n",
        "\n",
        "            df = pd.DataFrame(data=data)\n",
        "            # Save locally as csv\n",
        "            df.to_csv('flow_' + model_type + \"_\" + feature_type +\n",
        "                      '.csv', sep=',', index=False)\n",
        "            # save model object as a pickle\n",
        "\n",
        "        #correct += pred.eq(label).sum().item()\n",
        "\n",
        "    #total = 0\n",
        "    #for data in loader.dataset:\n",
        "    #total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "\n",
        "    return loss.item(), r2\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ],
      "metadata": {
        "id": "lPO1YankcYkn"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(arg):\n",
        "\n",
        "    args = objectview(arg)\n",
        "    train_losses, val_losses, test_losses, best_model, test_data = train(args)\n",
        "\n",
        "    #print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
        "    print(\"Minimum validation loss: {0}\".format(min(val_losses)))\n",
        "    print(\"Minimum test loss: {0}\".format(min(test_losses)))\n",
        "    # Run test for our best model to save the predictions!\n",
        "    test(test_data, best_model, save_model_preds=True,\n",
        "         model_type=args.model_type, feature_type=args.feature_type)\n",
        "\n",
        "    plt.title(\"Migration Flow Prediction L1 Loss\")\n",
        "    plt.plot(train_losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "    plt.plot(val_losses, label=\"validation loss\" + \" - \" + args.model_type)\n",
        "    plt.plot(test_losses, label=\"test loss\" + \" - \" + args.model_type)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "292GY-nDytsK"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running models"
      ],
      "metadata": {
        "id": "0viIPXr1zaSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 3,\n",
        "    'hidden_dim': 64,\n",
        "    \"out_dim\": 1,\n",
        "    'dropout': 0.5,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 100,\n",
        "    'model_type': \"GCN\",\n",
        "    'batch_size': 32,\n",
        "    'heads': 1,\n",
        "    'opt': 'adam',\n",
        "    'opt_scheduler': 'none',\n",
        "    'opt_restart': 0,\n",
        "    'weight_decay': 5e-3,\n",
        "    'feature_type': 'full',\n",
        "    'dataset': data_full\n",
        "}\n",
        "\n",
        "args_GraphSage = args.copy()\n",
        "args_GraphSage[\"model_type\"] = \"GraphSage\"\n",
        "\n",
        "args_GAT = args.copy()\n",
        "args_GAT[\"model_type\"] = \"GAT\"\n",
        "args_GAT[\"heads\"] = 2"
      ],
      "metadata": {
        "id": "y_y9kbmLmR5d"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline(args_GraphSage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ey4ndok86A19",
        "outputId": "40ab3ee7-982a-43a3-f3a1-530337295c77"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/100 [00:00<?, ?Epochs/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Training Loss 154.27269, Training R2 -0.07302 Validation Loss 153.77066 Validation R2 -0.0725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   1%|          | 1/100 [00:01<01:41,  1.03s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Training Loss 151.86902, Training R2 -0.07061 Validation Loss 153.34454 Validation R2 -0.07208\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 2/100 [00:02<01:44,  1.07s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Training Loss 146.87949, Training R2 -0.06517 Validation Loss 152.9232 Validation R2 -0.07163\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 3/100 [00:03<01:52,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Training Loss 139.02621, Training R2 -0.05666 Validation Loss 152.5677 Validation R2 -0.07125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 4/100 [00:04<02:02,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Training Loss 129.38895, Training R2 -0.04476 Validation Loss 152.21307 Validation R2 -0.07088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▌         | 5/100 [00:06<02:09,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Training Loss 123.01289, Training R2 -0.03048 Validation Loss 151.50714 Validation R2 -0.07008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 6/100 [00:07<02:05,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Training Loss 120.08228, Training R2 -0.0204 Validation Loss 149.67894 Validation R2 -0.06806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 7/100 [00:08<01:56,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Training Loss 118.23846, Training R2 -0.01914 Validation Loss 145.69083 Validation R2 -0.06432\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 8/100 [00:09<01:50,  1.21s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Training Loss 117.17096, Training R2 -0.02573 Validation Loss 140.99507 Validation R2 -0.06038\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 9/100 [00:10<01:46,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Training Loss 116.4174, Training R2 -0.02449 Validation Loss 137.28931 Validation R2 -0.05738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 10/100 [00:12<01:43,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Training Loss 115.93819, Training R2 -0.0208 Validation Loss 134.55278 Validation R2 -0.05522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 11/100 [00:13<01:40,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Training Loss 115.74918, Training R2 -0.0182 Validation Loss 132.66148 Validation R2 -0.05376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 12/100 [00:14<01:38,  1.12s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Training Loss 115.63985, Training R2 -0.01913 Validation Loss 131.36037 Validation R2 -0.05276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 13/100 [00:15<01:36,  1.11s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Training Loss 115.6037, Training R2 -0.02121 Validation Loss 130.55223 Validation R2 -0.05215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 14/100 [00:16<01:35,  1.11s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Training Loss 115.6626, Training R2 -0.02221 Validation Loss 130.09659 Validation R2 -0.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▌        | 15/100 [00:17<01:37,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Training Loss 115.70473, Training R2 -0.02216 Validation Loss 129.83234 Validation R2 -0.05158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 16/100 [00:19<01:44,  1.24s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Training Loss 115.73466, Training R2 -0.02077 Validation Loss 129.69806 Validation R2 -0.05146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 17/100 [00:20<01:48,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Training Loss 115.69785, Training R2 -0.01925 Validation Loss 129.64238 Validation R2 -0.05141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 18/100 [00:21<01:43,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Training Loss 115.71612, Training R2 -0.01846 Validation Loss 129.62483 Validation R2 -0.05138\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 19/100 [00:22<01:35,  1.18s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Training Loss 115.60188, Training R2 -0.0196 Validation Loss 129.62415 Validation R2 -0.05137\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 20/100 [00:23<01:32,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Training Loss 115.47437, Training R2 -0.02135 Validation Loss 129.58669 Validation R2 -0.05133\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 21/100 [00:25<01:36,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Training Loss 115.44753, Training R2 -0.02174 Validation Loss 129.50998 Validation R2 -0.05124\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 22/100 [00:26<01:30,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Training Loss 115.38972, Training R2 -0.02107 Validation Loss 129.41982 Validation R2 -0.05112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 23/100 [00:27<01:26,  1.12s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Training Loss 115.3184, Training R2 -0.02017 Validation Loss 129.33725 Validation R2 -0.05102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 24/100 [00:28<01:25,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Training Loss 115.26079, Training R2 -0.01906 Validation Loss 129.28467 Validation R2 -0.05094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▌       | 25/100 [00:29<01:23,  1.12s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Training Loss 115.24294, Training R2 -0.01894 Validation Loss 129.26729 Validation R2 -0.05091\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 26/100 [00:30<01:22,  1.12s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Training Loss 115.28133, Training R2 -0.01974 Validation Loss 129.25404 Validation R2 -0.05088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 27/100 [00:31<01:25,  1.18s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Training Loss 115.2791, Training R2 -0.02075 Validation Loss 129.23137 Validation R2 -0.05083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 28/100 [00:33<01:31,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Training Loss 115.18774, Training R2 -0.0215 Validation Loss 129.22252 Validation R2 -0.05078\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 29/100 [00:34<01:35,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Training Loss 115.15984, Training R2 -0.02097 Validation Loss 129.18886 Validation R2 -0.05069\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 30/100 [00:35<01:27,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Training Loss 115.17109, Training R2 -0.02009 Validation Loss 129.09303 Validation R2 -0.05054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 31/100 [00:36<01:21,  1.18s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Training Loss 115.19109, Training R2 -0.01958 Validation Loss 128.93799 Validation R2 -0.05036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 32/100 [00:38<01:18,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Training Loss 115.11797, Training R2 -0.01916 Validation Loss 128.72285 Validation R2 -0.05014\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 33/100 [00:39<01:16,  1.14s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Training Loss 115.11491, Training R2 -0.01985 Validation Loss 128.4516 Validation R2 -0.04989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 34/100 [00:40<01:14,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Training Loss 115.12862, Training R2 -0.02078 Validation Loss 128.12677 Validation R2 -0.04957\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▌      | 35/100 [00:41<01:13,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Training Loss 115.04768, Training R2 -0.02083 Validation Loss 127.69405 Validation R2 -0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 36/100 [00:42<01:12,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Training Loss 115.12316, Training R2 -0.02062 Validation Loss 127.21437 Validation R2 -0.04857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 37/100 [00:43<01:11,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Training Loss 115.06749, Training R2 -0.0199 Validation Loss 126.71794 Validation R2 -0.04802\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 38/100 [00:44<01:09,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Training Loss 115.12096, Training R2 -0.01957 Validation Loss 126.22997 Validation R2 -0.04749\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  39%|███▉      | 39/100 [00:46<01:15,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Training Loss 115.07683, Training R2 -0.01942 Validation Loss 125.75024 Validation R2 -0.04698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 40/100 [00:47<01:19,  1.32s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Training Loss 115.03349, Training R2 -0.02029 Validation Loss 125.27206 Validation R2 -0.04645\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 41/100 [00:49<01:21,  1.37s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Training Loss 115.05546, Training R2 -0.02054 Validation Loss 124.74787 Validation R2 -0.04581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 42/100 [00:50<01:15,  1.30s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Training Loss 115.02057, Training R2 -0.02044 Validation Loss 124.17535 Validation R2 -0.04506\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  43%|████▎     | 43/100 [00:51<01:10,  1.24s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Training Loss 115.11138, Training R2 -0.01983 Validation Loss 123.57008 Validation R2 -0.04426\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 44/100 [00:52<01:07,  1.21s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Training Loss 115.00351, Training R2 -0.01941 Validation Loss 122.98028 Validation R2 -0.04348\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  45%|████▌     | 45/100 [00:53<01:04,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 46: Training Loss 115.064, Training R2 -0.01932 Validation Loss 122.35735 Validation R2 -0.04267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  46%|████▌     | 46/100 [00:55<01:07,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Training Loss 115.04477, Training R2 -0.02004 Validation Loss 121.7139 Validation R2 -0.04179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  47%|████▋     | 47/100 [00:56<01:04,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Training Loss 115.01355, Training R2 -0.02019 Validation Loss 121.09138 Validation R2 -0.04086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 48/100 [00:57<01:01,  1.19s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Training Loss 115.04755, Training R2 -0.02026 Validation Loss 120.55753 Validation R2 -0.03998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 49/100 [00:58<00:59,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Training Loss 115.05676, Training R2 -0.01976 Validation Loss 120.08873 Validation R2 -0.03918\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 50/100 [00:59<00:59,  1.20s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 51: Training Loss 114.97459, Training R2 -0.01954 Validation Loss 119.69054 Validation R2 -0.03846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 51/100 [01:01<01:03,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52: Training Loss 115.05749, Training R2 -0.01947 Validation Loss 119.31978 Validation R2 -0.03774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 52/100 [01:02<01:04,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53: Training Loss 115.04285, Training R2 -0.01925 Validation Loss 118.91207 Validation R2 -0.03694\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 53/100 [01:04<01:03,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 54: Training Loss 114.97117, Training R2 -0.01966 Validation Loss 118.47143 Validation R2 -0.03605\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 54/100 [01:05<00:59,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55: Training Loss 114.99117, Training R2 -0.01984 Validation Loss 118.05011 Validation R2 -0.03516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▌    | 55/100 [01:06<00:55,  1.24s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 56: Training Loss 115.0118, Training R2 -0.0197 Validation Loss 117.66876 Validation R2 -0.03434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 56/100 [01:07<00:53,  1.21s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57: Training Loss 114.97389, Training R2 -0.0199 Validation Loss 117.33781 Validation R2 -0.03354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 57/100 [01:08<00:50,  1.18s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58: Training Loss 115.01611, Training R2 -0.01992 Validation Loss 117.00708 Validation R2 -0.03267\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 58/100 [01:09<00:48,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59: Training Loss 114.98219, Training R2 -0.01953 Validation Loss 116.67328 Validation R2 -0.03178\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 59/100 [01:10<00:46,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60: Training Loss 114.99352, Training R2 -0.0196 Validation Loss 116.35562 Validation R2 -0.0309\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 60/100 [01:12<00:45,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61: Training Loss 115.00292, Training R2 -0.02012 Validation Loss 116.07464 Validation R2 -0.03006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 61/100 [01:13<00:44,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62: Training Loss 115.0062, Training R2 -0.02017 Validation Loss 115.85519 Validation R2 -0.02931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 62/100 [01:14<00:44,  1.18s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63: Training Loss 115.01406, Training R2 -0.02038 Validation Loss 115.70009 Validation R2 -0.02868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 63/100 [01:15<00:47,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64: Training Loss 115.00414, Training R2 -0.01972 Validation Loss 115.58182 Validation R2 -0.02813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 64/100 [01:17<00:48,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65: Training Loss 114.98125, Training R2 -0.01949 Validation Loss 115.49011 Validation R2 -0.0277\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▌   | 65/100 [01:18<00:46,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66: Training Loss 114.97951, Training R2 -0.0195 Validation Loss 115.39768 Validation R2 -0.0273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 66/100 [01:19<00:43,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67: Training Loss 114.9889, Training R2 -0.01967 Validation Loss 115.29097 Validation R2 -0.02681\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 67/100 [01:21<00:40,  1.23s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68: Training Loss 115.0296, Training R2 -0.01977 Validation Loss 115.17774 Validation R2 -0.02624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 68/100 [01:22<00:38,  1.20s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69: Training Loss 114.96145, Training R2 -0.01966 Validation Loss 115.09392 Validation R2 -0.02581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 69/100 [01:23<00:36,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70: Training Loss 114.98169, Training R2 -0.01963 Validation Loss 115.04208 Validation R2 -0.02557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 70/100 [01:24<00:34,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71: Training Loss 115.00486, Training R2 -0.01992 Validation Loss 114.97459 Validation R2 -0.02518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 71/100 [01:25<00:33,  1.14s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72: Training Loss 115.00142, Training R2 -0.01987 Validation Loss 114.87696 Validation R2 -0.02446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 72/100 [01:26<00:31,  1.14s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73: Training Loss 114.98026, Training R2 -0.01924 Validation Loss 114.79922 Validation R2 -0.02385\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  73%|███████▎  | 73/100 [01:27<00:30,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74: Training Loss 115.00912, Training R2 -0.01933 Validation Loss 114.77545 Validation R2 -0.02373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  74%|███████▍  | 74/100 [01:29<00:31,  1.21s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75: Training Loss 114.99809, Training R2 -0.02018 Validation Loss 114.73048 Validation R2 -0.02327\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▌  | 75/100 [01:30<00:32,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76: Training Loss 114.95381, Training R2 -0.01948 Validation Loss 114.71533 Validation R2 -0.02305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 76/100 [01:32<00:32,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77: Training Loss 114.94216, Training R2 -0.01946 Validation Loss 114.72752 Validation R2 -0.02314\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 77/100 [01:33<00:30,  1.32s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78: Training Loss 114.9934, Training R2 -0.01948 Validation Loss 114.73009 Validation R2 -0.02318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 78/100 [01:34<00:27,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79: Training Loss 114.98596, Training R2 -0.01991 Validation Loss 114.67795 Validation R2 -0.02256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 79/100 [01:35<00:25,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80: Training Loss 114.94648, Training R2 -0.01955 Validation Loss 114.6378 Validation R2 -0.02225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 80/100 [01:36<00:23,  1.19s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81: Training Loss 114.93491, Training R2 -0.01974 Validation Loss 114.59325 Validation R2 -0.02175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 81/100 [01:37<00:22,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82: Training Loss 114.97069, Training R2 -0.02004 Validation Loss 114.56714 Validation R2 -0.0213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 82/100 [01:38<00:20,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83: Training Loss 114.91239, Training R2 -0.01955 Validation Loss 114.55355 Validation R2 -0.02106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 83/100 [01:40<00:19,  1.14s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84: Training Loss 114.96896, Training R2 -0.01966 Validation Loss 114.53921 Validation R2 -0.02072\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 84/100 [01:41<00:17,  1.11s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85: Training Loss 114.92308, Training R2 -0.01896 Validation Loss 114.54535 Validation R2 -0.02105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▌ | 85/100 [01:42<00:16,  1.08s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86: Training Loss 114.97093, Training R2 -0.02004 Validation Loss 114.53008 Validation R2 -0.02049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 86/100 [01:43<00:16,  1.16s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87: Training Loss 114.98105, Training R2 -0.01936 Validation Loss 114.52773 Validation R2 -0.02042\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 87/100 [01:44<00:16,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 88: Training Loss 114.93988, Training R2 -0.01939 Validation Loss 114.53187 Validation R2 -0.02044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 88/100 [01:46<00:15,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89: Training Loss 115.00603, Training R2 -0.01983 Validation Loss 114.53499 Validation R2 -0.02045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 89/100 [01:47<00:14,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90: Training Loss 114.90001, Training R2 -0.01952 Validation Loss 114.53108 Validation R2 -0.01994\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 90/100 [01:48<00:12,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91: Training Loss 114.97816, Training R2 -0.01878 Validation Loss 114.54008 Validation R2 -0.02094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 91/100 [01:49<00:10,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92: Training Loss 115.00874, Training R2 -0.02119 Validation Loss 114.5538 Validation R2 -0.01836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  92%|█████████▏| 92/100 [01:51<00:09,  1.19s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93: Training Loss 114.99121, Training R2 -0.01693 Validation Loss 114.51437 Validation R2 -0.02024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 93/100 [01:52<00:08,  1.17s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94: Training Loss 115.01133, Training R2 -0.02159 Validation Loss 114.51907 Validation R2 -0.01978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 94/100 [01:53<00:06,  1.15s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95: Training Loss 114.97518, Training R2 -0.02065 Validation Loss 114.56509 Validation R2 -0.01866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▌| 95/100 [01:54<00:05,  1.14s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96: Training Loss 114.99364, Training R2 -0.01812 Validation Loss 114.54431 Validation R2 -0.01942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 96/100 [01:55<00:04,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97: Training Loss 114.94566, Training R2 -0.01943 Validation Loss 114.53598 Validation R2 -0.02029\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 97/100 [01:56<00:03,  1.13s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98: Training Loss 114.95129, Training R2 -0.02106 Validation Loss 114.55994 Validation R2 -0.01926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 98/100 [01:58<00:02,  1.23s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99: Training Loss 114.94418, Training R2 -0.01908 Validation Loss 114.54354 Validation R2 -0.01862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 99/100 [01:59<00:01,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100: Training Loss 114.99126, Training R2 -0.01861 Validation Loss 114.49947 Validation R2 -0.01901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 100/100 [02:01<00:00,  1.21s/Epochs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum validation loss: 114.49946594238281\n",
            "Minimum test loss: 113.1100845336914\n",
            "Saving Model Predictions for Model Type GraphSage\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVopQ76V9ni0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NgKNmXav-bdP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}