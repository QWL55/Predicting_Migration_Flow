{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QWL55/Predicting_Migration_Flow/blob/main/notebook/CS224W_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuXWJLEm2UWS"
      },
      "source": [
        "# **CS224W - Final Project**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gzsP50bF6Gb"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCK7krJdp4o8"
      },
      "source": [
        "# Setup\n",
        "First let us check which version of PyTorch you are running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vkP8pA1qBE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da3ed69-22cd-4d66-8090-ffdf089c4df9"
      },
      "source": [
        "# Install torch geometric\n",
        "import os\n",
        "import torch\n",
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git\n",
        "!pip install -U -q PyDrive"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_scatter-2.1.2%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2+pt25cu121\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.5.1+cu121.html\n",
            "Collecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu121/torch_sparse-0.6.18%2Bpt25cu121-cp310-cp310-linux_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-sparse) (1.13.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy->torch-sparse) (1.26.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18+pt25cu121\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.6.1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for deepsnap (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DP_yEQZ0NVW"
      },
      "source": [
        "# 1) GNN: Link Regression Task\n",
        "\n",
        "In this section we will build our baseline graph neural network using PyTorch Geometric. Then we will apply it to the task of predicting the volume of migration flow (link regression).\n",
        "\n",
        "Specifically, we will use GCN as the foundation for the graph neural network ([Kipf et al. (2017)](https://arxiv.org/pdf/1609.02907.pdf)). To do so, we will work with PyG's built-in `GCNConv` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4CcOUEoInjD"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# The PyG built-in GCNConv\n",
        "import torch_geometric\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import negative_sampling\n",
        "import torch_geometric.transforms as T"
      ],
      "metadata": {
        "id": "FT_w3_lVcxdS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L68uxydJVqUx",
        "outputId": "6c8358d8-b228-40ee-b5ef-da25cd9e8c60"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# change the path to your project folder\n",
        "os.chdir('/content/drive/MyDrive/Stanford SOC/CS224W/final_projects')"
      ],
      "metadata": {
        "id": "l9GJF29jV75D"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoMTUJkjdXDz",
        "outputId": "53ba63dc-1abf-45bd-874d-067070ed3368"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['CS224W_Colab_2.ipynb',\n",
              " 'dataset',\n",
              " 'county_flow.csv',\n",
              " 'county_node_info.csv',\n",
              " 'flow_GraphSage.csv',\n",
              " 'flow_GCN.csv',\n",
              " '.ipynb_checkpoints',\n",
              " 'flow_GraphSage_full.csv',\n",
              " 'flow_GCN_full.csv',\n",
              " 'CS224W_Final_Project.ipynb']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IK9z0wQIwzQ"
      },
      "source": [
        "## Load and Preprocess the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "\n",
        "# Load the datasets\n",
        "county_flow_df = pd.read_csv('county_flow.csv', dtype={\"fips_orig\": str, \"fips_dest\": str})\n",
        "county_node_df = pd.read_csv('county_node_info.csv', dtype={\"GEOID\": str})\n",
        "\n",
        "# Step 1: Create a mapping from GEOID to index and\n",
        "# map fips_orig and fips_dest in county_flow_df to indices\n",
        "geo_to_index = {geo_id: idx for idx, geo_id in enumerate(county_node_df['GEOID'])}\n",
        "\n",
        "county_flow_df['src'] = county_flow_df['fips_orig'].map(geo_to_index)\n",
        "county_flow_df['dst'] = county_flow_df['fips_dest'].map(geo_to_index)\n",
        "\n",
        "# Drop any rows with missing mappings (i.e., if a fips code doesn't exist in county_node_df)\n",
        "county_flow_df = county_flow_df.dropna(subset=['src', 'dst']).astype({'src': int, 'dst': int})\n",
        "\n",
        "# Step 2: Extract the edge list and label\n",
        "edge_index_df = county_flow_df[['src', 'dst']]\n",
        "edge_index = torch.tensor(edge_index_df.values.T, dtype=torch.long)\n",
        "\n",
        "edge_labels = county_flow_df['flow'].values\n",
        "edge_labels = torch.tensor(edge_labels, dtype=torch.long)\n",
        "\n",
        "#Create a mapping dictionary from edge_index to edge_labels\n",
        "edge_maps = {\n",
        "    tuple(edge): label for edge, label in zip(edge_index.T.tolist(), edge_labels.tolist())\n",
        "}\n",
        "\n",
        "def load_process_data(feat_type):\n",
        "    # Step 3: Create two versions of county_node_features\n",
        "    if feat_type == 'full':\n",
        "        # includes all columns except GEOID\n",
        "        columns_to_drop = ['GEOID']\n",
        "    elif feat_type == 'simple':\n",
        "        # excludes columns with \"feature\" in their names\n",
        "        columns_to_drop = ['GEOID'] + [col for col in county_node_df.columns if 'feature' in col.lower()]\n",
        "    elif feat_type == 'pdfm':\n",
        "        # include only pdfm features\n",
        "        columns_to_drop = ['GEOID'] + [col for col in county_node_df.columns if 'feature' not in col.lower()]\n",
        "\n",
        "    # select relevant features\n",
        "    county_node_features = county_node_df.drop(columns=columns_to_drop, errors='ignore').values\n",
        "    county_node_features = torch.tensor(county_node_features, dtype=torch.float)\n",
        "\n",
        "    # Create PyG Data object\n",
        "    data = Data(x=county_node_features, edge_index=edge_index, y=edge_labels,\n",
        "                edge_label=edge_labels)\n",
        "    data.num_node_features = county_node_features.shape[1]\n",
        "    data.num_classes = 1\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "NojfEz27VVQa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_full = load_process_data('full')\n",
        "data_simple = load_process_data('simple')\n",
        "data_pdfm = load_process_data('pdfm')\n",
        "\n",
        "print(\"Data with full features:\")\n",
        "print(data_full)\n",
        "print(\"\\nData with simple features:\")\n",
        "print(data_simple)\n",
        "print(\"\\nData with pdfm features:\")\n",
        "print(data_pdfm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JC-KuR9_aDXT",
        "outputId": "72488fef-0a9f-475b-aa7b-94e4998ad661"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data with full features:\n",
            "Data(x=[3116, 339], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=339, num_classes=1)\n",
            "\n",
            "Data with simple features:\n",
            "Data(x=[3116, 9], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=9, num_classes=1)\n",
            "\n",
            "Data with pdfm features:\n",
            "Data(x=[3116, 330], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=330, num_classes=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohagw6pmacSY",
        "outputId": "43476053-615d-4d6b-a024-999f2d3a51b4"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(x=[3116, 339], edge_index=[2, 107568], y=[107568], edge_label=[107568], num_node_features=339, num_classes=1)"
            ]
          },
          "metadata": {},
          "execution_count": 275
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splitting\n",
        "transform = T.Compose([T.ToSparseTensor(),\n",
        "                       T.RandomLinkSplit(is_undirected=False,\n",
        "                                         neg_sampling_ratio=0.5,\n",
        "                                         split_labels=True)])\n",
        "\n",
        "train_data, val_data, test_data = transform(data_simple)\n",
        "#train_data, val_data, test_data = transform(data_simple)\n",
        "print(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kRUnj1OilrWv",
        "outputId": "c34c02a5-642e-4a9d-e1c7-be8009b91253"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3116, 9], y=[75299], num_node_features=9, num_classes=1, adj_t=[3116, 3116, nnz=107568], edge_index=[2, 75299], pos_edge_label=[75299], pos_edge_label_index=[2, 75299], neg_edge_label=[37649], neg_edge_label_index=[2, 37649])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = edge_mapping(val_data)"
      ],
      "metadata": {
        "id": "mWePd8WbXQ7B"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_data.pos_edge_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbJuunX8HPa2",
        "outputId": "d3bbdbc9-afee-4933-d8ba-c043e01d0104"
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10756])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[k for k, v in geo_to_index.items() if v == 2792]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3eI528JdNlL",
        "outputId": "1a968f1e-cb05-40a2-bf61-24695e7744d7"
      },
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['050025']"
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data.pos_edge_label_index[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pt5v570NdVnx",
        "outputId": "de8c6748-dd7a-4fda-da0c-86d5f19bb3df"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2792, 2662, 2436,  ..., 3000, 2199,  758])"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = county_node_df[(county_node_df['GEOID'] == \"050025\")]\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM4V5p-rPzre",
        "outputId": "8af4dcca-211a-4a61-c6ff-991dc057621f"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       GEOID  tot_pop  median_inc     unemp      pov    age_65  diveristy_idx  \\\n",
            "2792  050025    43609       50917  0.060457  0.13124  0.191726       0.121224   \n",
            "\n",
            "      hou_burd  vote_share  crime_rate  ...  feature320    feature321  \\\n",
            "2792  0.001952    0.633532    0.028595  ...   -0.000013 -1.200000e-07   \n",
            "\n",
            "      feature322  feature323    feature324  feature325  feature326  \\\n",
            "2792   -0.000314   -0.000869 -3.000000e-08   -0.000722        -0.0   \n",
            "\n",
            "        feature327  feature328    feature329  \n",
            "2792 -1.000000e-08        -0.0 -2.000000e-08  \n",
            "\n",
            "[1 rows x 340 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = val_data.x[val_data.pos_edge_label_index[0]]\n",
        "t2 = val_data.x[val_data.pos_edge_label_index[1]]\n",
        "\n",
        "cat = torch.cat([t1, t2], dim=-1).shape"
      ],
      "metadata": {
        "id": "9g2PYbuuHc3_"
      },
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cat([t1, t2], dim=1) == torch.cat([t1, t2], dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rywMsnvAdrEs",
        "outputId": "364bfbee-5372-4501-a164-0bd5fda6ad7b"
      },
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        ...,\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#val_data.pos_edge_label_index.T.tolist()\n",
        "original_edges = val_data.pos_edge_label_index.T.tolist()\n",
        "original_labels = val_data.pos_edge_label.tolist()\n",
        "\n",
        "# Ensure alignment by creating a dictionary\n",
        "edge_to_label = {tuple(edge): label for edge, label in zip(original_edges, original_labels)}"
      ],
      "metadata": {
        "id": "i-IMMN5PYHLM"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#edge_to_label"
      ],
      "metadata": {
        "id": "gG5O0yW0Y3aX"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_mapping(data):\n",
        "    # Create a mapping of edge to label\n",
        "    #original_edges = data.edge_label_index.T.tolist()\n",
        "    #original_labels = data.pos_edge_label.tolist()\n",
        "\n",
        "    # Ensure alignment by creating a dictionary\n",
        "    #edge_to_label = {tuple(edge): label for edge, label in zip(original_edges, original_labels)}\n",
        "\n",
        "    # Reassign labels in the order of pos_edge_label_index\n",
        "    aligned_labels = []\n",
        "    for edge in data.pos_edge_label_index.T.tolist():\n",
        "        aligned_labels.append(edge_maps[tuple(edge)])\n",
        "\n",
        "    # Convert aligned labels back to a tensor\n",
        "    data.pos_edge_label = torch.tensor(aligned_labels, dtype=torch.float)\n",
        "\n",
        "    return data\n",
        "\n",
        "train_data = edge_mapping(train_data)\n",
        "\n",
        "# Check if pos_edge_label corresponds to pos_edge_label_index\n",
        "for i, (src, dst) in enumerate(train_data.pos_edge_label_index.T):\n",
        "    label = train_data.pos_edge_label[i]\n",
        "    print(f\"Edge ({src.item()}, {dst.item()}) -> Label: {label.item()}\")\n",
        "    if i == 2:\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s623eGJFQUvF",
        "outputId": "56644744-188f-4286-eaf2-53d3a8c73ca1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edge (306, 2513) -> Label: 48.0\n",
            "Edge (316, 1188) -> Label: 548.0\n",
            "Edge (504, 473) -> Label: 104.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.pos_edge_label_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fb-kx5pGcaL6",
        "outputId": "f6416e79-6346-4bd5-cc9e-8ed72502b430"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 224, 2201, 2302,  ..., 2443,  722, 1640],\n",
              "        [2964, 1040, 2334,  ..., 2446, 1020, 3109]])"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.pos_edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0MdEd1WcsBD",
        "outputId": "acb438f7-080c-4f72-c2c0-0c1493ef9f55"
      },
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 47.,  42., 293.,  ...,  95.,  28.,  91.])"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0owWO0e1Xz2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = county_flow_df[(county_flow_df['src'] == 2201) & (county_flow_df['dst'] == 1040)]\n",
        "print(filtered_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl9dWI1kcowK",
        "outputId": "a71204e9-a338-4f39-eccd-93901a3f66c4"
      },
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      fips_orig fips_dest  flow   src   dst\n",
            "77098    041033    021107    42  2201  1040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "county_node_df = pd.read_csv('county_node_info.csv', dtype={\"GEOID\": str})\n",
        "county_flow_df = pd.read_csv('county_flow.csv', dtype={\"fips_orig\": str, \"fips_dest\": str})\n",
        "\n",
        "# Step 1: Create a mapping from GEOID to index and\n",
        "# map fips_orig and fips_dest in county_flow_df to indices\n",
        "geo_to_index = {geo_id: idx for idx, geo_id in enumerate(county_node_df['GEOID'])}\n",
        "\n",
        "county_flow_df['src'] = county_flow_df['fips_orig'].map(geo_to_index)\n",
        "county_flow_df['dst'] = county_flow_df['fips_dest'].map(geo_to_index)\n",
        "\n",
        "\n",
        "# Drop any rows with missing mappings (i.e., if a fips code doesn't exist in county_node_df)\n",
        "county_flow_df = county_flow_df.dropna(subset=['src', 'dst']).astype({'src': int, 'dst': int})"
      ],
      "metadata": {
        "id": "FmZXGb6G9Mig"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building"
      ],
      "metadata": {
        "id": "NKr3msRGdgQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch_scatter\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch_geometric.nn as pyg_nn\n",
        "import torch_geometric.utils as pyg_utils\n",
        "\n",
        "from torch import Tensor\n",
        "from typing import Union, Tuple, Optional\n",
        "from torch_geometric.typing import (OptPairTensor, Adj, Size, NoneType,\n",
        "                                    OptTensor)\n",
        "\n",
        "from torch.nn import Parameter, Linear\n",
        "from torch_sparse import SparseTensor, set_diag\n",
        "from torch_geometric.nn.conv import MessagePassing\n",
        "from torch_geometric.utils import remove_self_loops, add_self_loops, softmax\n",
        "\n",
        "class GNNStack(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, args, emb=False):\n",
        "        super(GNNStack, self).__init__()\n",
        "        conv_model = self.build_conv_model(args.model_type)\n",
        "        self.convs = nn.ModuleList()\n",
        "        self.bns = nn.ModuleList()\n",
        "        self.convs.append(conv_model(input_dim, hidden_dim))\n",
        "        assert (args.num_layers >= 1), 'Number of layers is not >=1'\n",
        "        for l in range(args.num_layers-1):\n",
        "            self.convs.append(conv_model(args.heads * hidden_dim, hidden_dim))\n",
        "\n",
        "        # post-message-passing\n",
        "        # times 2 because we concatenate node embedding\n",
        "        self.link_regressor = nn.Sequential(\n",
        "            nn.Linear(2 * args.heads * hidden_dim, hidden_dim),\n",
        "            nn.Dropout(args.dropout),\n",
        "            nn.Linear(hidden_dim, output_dim))\n",
        "\n",
        "        self.dropout = args.dropout\n",
        "\n",
        "        for _ in range(args.num_layers):\n",
        "            self.bns.append(torch.nn.BatchNorm1d(args.heads *hidden_dim))\n",
        "\n",
        "        self.num_layers = args.num_layers\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.emb = emb\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        # Reset parameters of convolutional layers\n",
        "        for conv in self.convs:\n",
        "            if hasattr(conv, 'reset_parameters'):\n",
        "                conv.reset_parameters()\n",
        "        # Reset parameters of link_regressor layers\n",
        "        for layer in self.link_regressor:\n",
        "            if isinstance(layer, nn.Linear):\n",
        "                layer.reset_parameters()\n",
        "\n",
        "        for bn in self.bns:\n",
        "            bn.reset_parameters()\n",
        "\n",
        "\n",
        "    def build_conv_model(self, model_type):\n",
        "        if model_type == 'GraphSage':\n",
        "            return GraphSage\n",
        "        elif model_type == 'GCN':\n",
        "            return GCNConv\n",
        "        elif model_type == 'GAT':\n",
        "            return GAT\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, post_edge_index, neg_edge_index = data.x, data.pos_edge_label_index, data.neg_edge_label_index\n",
        "        out = x\n",
        "\n",
        "        edge_index = torch.cat([post_edge_index, neg_edge_index], dim=1)\n",
        "        for i in range(self.num_layers):\n",
        "            out = self.convs[i](out, post_edge_index)\n",
        "            out = self.bns[i](out)\n",
        "            out = self.prelu(out)\n",
        "            output = F.dropout(out, p=self.dropout,training=self.training)\n",
        "\n",
        "        if self.emb == True:\n",
        "            return out\n",
        "\n",
        "        return self.predict_edges(out, edge_index)\n",
        "\n",
        "    def predict_edges(self, node_features, edge_index):\n",
        "        # Extract source and destination node embeddings\n",
        "        node_features_src = node_features[edge_index[0]]  # Source nodes\n",
        "        node_features_dst = node_features[edge_index[1]]  # Destination nodes\n",
        "\n",
        "        # Combine embeddings (e.g., using dot product or concatenation)\n",
        "        edge_features = torch.cat([node_features_src, node_features_dst], dim=1)\n",
        "\n",
        "        # Predict edge values (continuous outputs)\n",
        "        edge_predictions = self.link_regressor(edge_features)\n",
        "\n",
        "        return edge_predictions\n",
        "\n",
        "    def loss(self, pred, label):\n",
        "        return F.l1_loss(pred, label)"
      ],
      "metadata": {
        "id": "aCp_9NGOdnoQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GraphSage\n"
      ],
      "metadata": {
        "id": "U9DtEZ2zdBcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GraphSage(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, normalize = True,\n",
        "                 bias = False, aggr=\"mean\", **kwargs):\n",
        "        super(GraphSage, self).__init__(**kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.normalize = normalize\n",
        "        self.aggr = aggr\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the (PyTorch) layers needed for the message and update functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embedding\n",
        "        #            for central node.\n",
        "        # self.lin_r is the linear transformation that you apply to aggregated\n",
        "        #            message from neighbors.\n",
        "        # Don't forget the bias as part of the linear layers!\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "        self.lin_r = nn.Linear(in_channels, out_channels, bias=bias)\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin_l.reset_parameters()\n",
        "        self.lin_r.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "        \"\"\"\"\"\"\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement message passing, as well as any post-processing (our update rule).\n",
        "        # 1. Call the propagate function to conduct the message passing.\n",
        "        #    1.1 See the description of propagate above or the following link for more information:\n",
        "        #        https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        #    1.2 We will only use the representation for neighbor nodes (x_j), so by default\n",
        "        #        we pass the same representation for central and neighbor nodes as x=(x, x).\n",
        "        # 2. Update our node embedding with skip connection from the previous layer.\n",
        "        # 3. If normalize is set, do L-2 normalization (defined in\n",
        "        #    torch.nn.functional)\n",
        "        out = self.propagate(edge_index, x=(x,x), size=size)\n",
        "        out = self.lin_l(x) + self.lin_r(out)\n",
        "        if self.normalize:\n",
        "            out = F.normalize(out, p=2, dim=-1)\n",
        "\n",
        "        return out\n",
        "\n",
        "    def message(self, x_j):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your message function here.\n",
        "        # Hint: Look at the formulation of the mean aggregation function, focusing on\n",
        "        # what message each neighboring node passes.\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = x_j\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "        # The axis along which to index number of nodes.\n",
        "        node_dim = self.node_dim\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter:\n",
        "        # https://pytorch-scatter.readthedocs.io/en/latest/functions/scatter.html#torch_scatter.scatter\n",
        "        #\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, dim=node_dim, reduce=self.aggr)\n",
        "\n",
        "        ############################################################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "FRy6nRB2dEWr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAT\n"
      ],
      "metadata": {
        "id": "lV2etmynxHZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GAT(MessagePassing):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, heads = 2,\n",
        "                 negative_slope = 0.2, dropout = 0., **kwargs):\n",
        "        super(GAT, self).__init__(node_dim=0, **kwargs)\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.heads = heads\n",
        "        self.negative_slope = negative_slope\n",
        "        self.dropout = dropout\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the layers needed for the message functions below.\n",
        "        # self.lin_l is the linear transformation that you apply to embeddings\n",
        "        # BEFORE message passing.\n",
        "        #\n",
        "        # Pay attention to dimensions of the linear layers, since we're using\n",
        "        # multi-head attention.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        self.lin_l = nn.Linear(in_channels, heads * out_channels, bias=False)\n",
        "        ############################################################################\n",
        "\n",
        "        self.lin_r = self.lin_l\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Define the attention parameters \\overrightarrow{a_l/r}^T in the above intro.\n",
        "        # You have to deal with multi-head scenarios.\n",
        "        # Use nn.Parameter instead of nn.Linear\n",
        "        # Our implementation is ~2 lines, but don't worry if you deviate from this.\n",
        "        self.att_l = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        self.att_r = nn.Parameter(torch.Tensor(1, heads, out_channels))\n",
        "        ############################################################################\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.xavier_uniform_(self.lin_l.weight)\n",
        "        nn.init.xavier_uniform_(self.lin_r.weight)\n",
        "        nn.init.xavier_uniform_(self.att_l)\n",
        "        nn.init.xavier_uniform_(self.att_r)\n",
        "\n",
        "    def forward(self, x, edge_index, size = None):\n",
        "\n",
        "        H, C = self.heads, self.out_channels\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement message passing, as well as any pre- and post-processing (our update rule).\n",
        "        # 1. First apply linear transformation to node embeddings, and split that\n",
        "        #    into multiple heads. We use the same representations for source and\n",
        "        #    target nodes, but apply different linear weights (W_l and W_r)\n",
        "        # 2. Calculate alpha vectors for central nodes (alpha_l) and neighbor nodes (alpha_r).\n",
        "        # 3. Call propagate function to conduct the message passing.\n",
        "        #    3.1 Remember to pass alpha = (alpha_l, alpha_r) as a parameter.\n",
        "        #    3.2 See there for more information: https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html\n",
        "        # 4. Transform the output back to the shape of [N, H * C].\n",
        "        # Our implementation is ~5 lines, but don't worry if you deviate from this.\n",
        "        x_l, x_r = self.lin_l(x).view(-1, H, C), self.lin_r(x).view(-1, H, C)\n",
        "        alpha_l = (x_l * self.att_l).sum(dim=-1)\n",
        "        alpha_r = (x_r * self.att_r).sum(dim=-1)\n",
        "\n",
        "        out = self.propagate(edge_index, x=(x_l,x_r), alpha=(alpha_l, alpha_r), size=size)\n",
        "        out = out.view(-1, H * C)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def message(self, x_j, alpha_j, alpha_i, index, ptr, size_i):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your message function. Putting the attention in message\n",
        "        # instead of in update is a little tricky.\n",
        "        # 1. Calculate the final attention weights using alpha_i and alpha_j,\n",
        "        #    and apply leaky Relu.\n",
        "        # 2. Calculate softmax over the neighbor nodes for all the nodes. Use\n",
        "        #    torch_geometric.utils.softmax instead of the one in Pytorch.\n",
        "        # 3. Apply dropout to attention weights (alpha).\n",
        "        # 4. Multiply embeddings and attention weights. As a sanity check, the output\n",
        "        #    should be of shape [E, H, C].\n",
        "        # 5. ptr (LongTensor, optional): If given, computes the softmax based on\n",
        "        #    sorted inputs in CSR representation. You can simply pass it to softmax.\n",
        "        # 6. size_i: corresponds to the num_nodes variable input to the torch.geometric.softmax method\n",
        "        # Our implementation is ~4-5 lines, but don't worry if you deviate from this.\n",
        "        alpha = alpha_i + alpha_j\n",
        "        out = F.leaky_relu(alpha, self.negative_slope)\n",
        "        out = torch_geometric.utils.softmax(out, index, ptr, size_i)\n",
        "        out = F.dropout(out, p=self.dropout, training=self.training)\n",
        "        out = x_j * out.unsqueeze(-1)\n",
        "        ############################################################################\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "    def aggregate(self, inputs, index, dim_size = None):\n",
        "\n",
        "        ############################################################################\n",
        "        # TODO: Your code here!\n",
        "        # Implement your aggregate function here.\n",
        "        # See here as how to use torch_scatter.scatter: https://pytorch-scatter.readthedocs.io/en/latest/_modules/torch_scatter/scatter.html\n",
        "        # Pay attention to \"reduce\" parameter is different from that in GraphSage.\n",
        "        # Our implementation is ~1 lines, but don't worry if you deviate from this.\n",
        "        out = torch_scatter.scatter(inputs, index, dim=0, dim_size=dim_size, reduce='sum')\n",
        "        ############################################################################\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "6tsoeQzjxJ9L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimizer"
      ],
      "metadata": {
        "id": "MQ6POCTRgi1O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def build_optimizer(args, params):\n",
        "    weight_decay = args.weight_decay\n",
        "    filter_fn = filter(lambda p : p.requires_grad, params)\n",
        "    if args.opt == 'adam':\n",
        "        optimizer = optim.Adam(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'sgd':\n",
        "        optimizer = optim.SGD(filter_fn, lr=args.lr, momentum=0.95, weight_decay=weight_decay)\n",
        "    elif args.opt == 'rmsprop':\n",
        "        optimizer = optim.RMSprop(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    elif args.opt == 'adagrad':\n",
        "        optimizer = optim.Adagrad(filter_fn, lr=args.lr, weight_decay=weight_decay)\n",
        "    if args.opt_scheduler == 'none':\n",
        "        return None, optimizer\n",
        "    elif args.opt_scheduler == 'step':\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=args.opt_decay_step, gamma=args.opt_decay_rate)\n",
        "    elif args.opt_scheduler == 'cos':\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args.opt_restart)\n",
        "    return scheduler, optimizer"
      ],
      "metadata": {
        "id": "H0nIkNBIgiIb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training and Evaluation"
      ],
      "metadata": {
        "id": "NvY_9LEXcUAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw3IQo05_f8k",
        "outputId": "5151f7b4-62a6-4fa7-a062-5c4e5d04f370"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.12.2)\n",
            "Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import DataLoader\n",
        "from tqdm import trange\n",
        "import matplotlib.pyplot as plt\n",
        "from torcheval.metrics.functional import r2_score\n",
        "#from sklearn.metrics import r2_score\n",
        "\n",
        "def train(args):\n",
        "\n",
        "    transform = T.Compose([T.ToSparseTensor(),\n",
        "                           T.RandomLinkSplit(is_undirected=False,\n",
        "                                             neg_sampling_ratio=0.5,\n",
        "                                             split_labels=True)])\n",
        "    dataset = args.dataset\n",
        "    train_data, val_data, test_data = transform(dataset)\n",
        "    train_data, val_data, test_data = edge_mapping(train_data), edge_mapping(val_data), edge_mapping(test_data)\n",
        "    #print(\"Node task. test set size:\", np.sum(dataset[0]['test_mask'].numpy()))\n",
        "    #test_loader = loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False)\n",
        "\n",
        "    # build model\n",
        "    model = GNNStack(dataset.num_node_features, args.hidden_dim, dataset.num_classes,\n",
        "                            args)\n",
        "    scheduler, opt = build_optimizer(args, model.parameters())\n",
        "\n",
        "    # train\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    test_losses = []\n",
        "    train_r2_scores = []\n",
        "    val_r2_scores = []\n",
        "    test_r2_scores = []\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    best_model = None\n",
        "\n",
        "    for epoch in trange(args.epochs, desc=\"Training\", unit=\"Epochs\"):\n",
        "        model.train()\n",
        "        #for batch in loader:\n",
        "        opt.zero_grad()\n",
        "        pred = model(train_data).squeeze(-1)\n",
        "        label = torch.cat([train_data.pos_edge_label, train_data.neg_edge_label]).float()\n",
        "        #label = train_data.pos_edge_label.float()\n",
        "        #pred = pred[batch.train_mask]\n",
        "        #label = label[batch.train_mask]\n",
        "        label = torch.log1p(label)\n",
        "        loss = model.loss(label, pred)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        train_r2 = r2_score(pred, label).item()\n",
        "        train_r2_scores.append(train_r2)\n",
        "\n",
        "        val_loss, val_r2 = test(val_data, model)\n",
        "        val_losses.append(val_loss)\n",
        "        val_r2_scores.append(val_r2)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {epoch + 1}: Training Loss {round(loss.item(), 5)}, \"\n",
        "            f\"Training R2 {round(train_r2, 5)}\",\n",
        "            f\"Validation Loss {round(val_loss, 5)}\",\n",
        "            f\"Validation R2 {round(val_r2, 5)}\"\n",
        "        )\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            best_model = copy.deepcopy(model)\n",
        "\n",
        "        test_loss, test_r2 = test(test_data, model)\n",
        "        test_losses.append(test_loss)\n",
        "        test_r2_scores.append(test_r2)\n",
        "\n",
        "    return train_losses, val_losses, test_losses, best_model, test_data\n",
        "\n",
        "\n",
        "def test(data, test_model, save_model_preds=False, model_type=None,\n",
        "         feature_type=None):\n",
        "    test_model.eval()\n",
        "\n",
        "    #correct = 0\n",
        "    # Note that Cora is only one graph!\n",
        "    with torch.no_grad():\n",
        "        # max(dim=1) returns values, indices tuple; only need indices\n",
        "        pred = test_model(data).squeeze(-1)\n",
        "        label = torch.cat([data.pos_edge_label, data.neg_edge_label]).float()\n",
        "        label = torch.log1p(label)\n",
        "        loss = test_model.loss(pred, label)\n",
        "        r2 = r2_score(pred, label).item()\n",
        "        #mask = data.val_mask if is_validation else data.test_mask\n",
        "        # node classification: only evaluate on nodes in test set\n",
        "        #pred = pred[mask]\n",
        "        #label = label[mask]\n",
        "\n",
        "        if save_model_preds:\n",
        "            print (\"Saving Model Predictions for Model Type\", model_type)\n",
        "\n",
        "            data = {}\n",
        "            data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
        "            data['label'] = label.view(-1).cpu().detach().numpy()\n",
        "\n",
        "            df = pd.DataFrame(data=data)\n",
        "            # Save locally as csv\n",
        "            df.to_csv('flow_' + model_type + \"_\" + feature_type +\n",
        "                      '.csv', sep=',', index=False)\n",
        "            # save model object as a pickle\n",
        "\n",
        "        #correct += pred.eq(label).sum().item()\n",
        "\n",
        "    #total = 0\n",
        "    #for data in loader.dataset:\n",
        "    #total += torch.sum(data.val_mask if is_validation else data.test_mask).item()\n",
        "\n",
        "    return loss.item(), r2\n",
        "\n",
        "class objectview(object):\n",
        "    def __init__(self, d):\n",
        "        self.__dict__ = d\n"
      ],
      "metadata": {
        "id": "lPO1YankcYkn"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(arg):\n",
        "\n",
        "    args = objectview(arg)\n",
        "    train_losses, val_losses, test_losses, best_model, test_data = train(args)\n",
        "\n",
        "        # Run test for our best model to save the predictions!\n",
        "    best_loss, best_r2 = test(test_data, best_model, save_model_preds=True,\n",
        "                              model_type=args.model_type, feature_type=args.feature_type)\n",
        "    #print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
        "    print(\"Minimum validation loss: {0}\".format(min(val_losses)))\n",
        "    print(\"Minimum test loss: {0}\".format(min(test_losses)))\n",
        "    print(\"Minimum test R2: {0}\".format(best_r2))\n",
        "\n",
        "    plt.title(\"Migration Flow Prediction L1 Loss\")\n",
        "    plt.plot(train_losses, label=\"training loss\" + \" - \" + args.model_type)\n",
        "    plt.plot(val_losses, label=\"validation loss\" + \" - \" + args.model_type)\n",
        "    plt.plot(test_losses, label=\"test loss\" + \" - \" + args.model_type)\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "292GY-nDytsK"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running models"
      ],
      "metadata": {
        "id": "0viIPXr1zaSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "args = {\n",
        "    'device': device,\n",
        "    'num_layers': 1,\n",
        "    'hidden_dim': 128,\n",
        "    \"out_dim\": 1,\n",
        "    'dropout': 0.2,\n",
        "    'lr': 0.01,\n",
        "    'epochs': 120,\n",
        "    'model_type': \"GCN\",\n",
        "    'batch_size': 32,\n",
        "    'heads': 1,\n",
        "    'opt': 'adam',\n",
        "    'opt_scheduler': 'none',\n",
        "    'opt_restart': 0,\n",
        "    'weight_decay': 5e-3,\n",
        "    'feature_type': 'full',\n",
        "    'dataset': data_full\n",
        "}\n",
        "\n",
        "args_GraphSage = args.copy()\n",
        "args_GraphSage[\"model_type\"] = \"GraphSage\"\n",
        "\n",
        "args_GAT = args.copy()\n",
        "args_GAT[\"model_type\"] = \"GAT\"\n",
        "args_GAT[\"heads\"] = 2"
      ],
      "metadata": {
        "id": "y_y9kbmLmR5d"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_pipeline(args_GraphSage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ey4ndok86A19",
        "outputId": "7b33f4e4-ddf1-4d1d-8cd1-e497e9bbdfb2"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   1%|          | 1/120 [00:01<03:53,  1.96s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Training Loss 2.77772, Training R2 -1.46467 Validation Loss 2.73577 Validation R2 -1.44342\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▏         | 2/120 [00:03<03:31,  1.79s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Training Loss 3.75502, Training R2 -3.99646 Validation Loss 2.79913 Validation R2 -1.56766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   2%|▎         | 3/120 [00:05<03:28,  1.78s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Training Loss 1.92847, Training R2 -0.03014 Validation Loss 2.79191 Validation R2 -1.51777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   3%|▎         | 4/120 [00:06<03:06,  1.61s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Training Loss 1.67092, Training R2 0.1974 Validation Loss 2.74903 Validation R2 -1.40615\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   4%|▍         | 5/120 [00:07<02:46,  1.45s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Training Loss 1.70935, Training R2 0.13616 Validation Loss 2.71794 Validation R2 -1.34851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   5%|▌         | 6/120 [00:09<02:35,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Training Loss 1.60181, Training R2 0.20734 Validation Loss 2.71116 Validation R2 -1.35127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   6%|▌         | 7/120 [00:10<02:27,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Training Loss 1.47206, Training R2 0.29921 Validation Loss 2.70621 Validation R2 -1.34535\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   7%|▋         | 8/120 [00:11<02:23,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Training Loss 1.595, Training R2 0.21798 Validation Loss 2.67794 Validation R2 -1.28081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 9/120 [00:12<02:19,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Training Loss 1.49162, Training R2 0.27087 Validation Loss 2.63363 Validation R2 -1.17598\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   8%|▊         | 10/120 [00:13<02:17,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Training Loss 1.42463, Training R2 0.30215 Validation Loss 2.60623 Validation R2 -1.09982\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   9%|▉         | 11/120 [00:15<02:13,  1.23s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11: Training Loss 1.47283, Training R2 0.27452 Validation Loss 2.60871 Validation R2 -1.08707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  10%|█         | 12/120 [00:16<02:20,  1.30s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12: Training Loss 1.40364, Training R2 0.34072 Validation Loss 2.62543 Validation R2 -1.11006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  11%|█         | 13/120 [00:18<02:30,  1.40s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13: Training Loss 1.40654, Training R2 0.36215 Validation Loss 2.62709 Validation R2 -1.11012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▏        | 14/120 [00:19<02:40,  1.51s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14: Training Loss 1.45485, Training R2 0.34117 Validation Loss 2.60229 Validation R2 -1.06281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  12%|█▎        | 15/120 [00:21<02:32,  1.45s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15: Training Loss 1.40062, Training R2 0.36172 Validation Loss 2.56084 Validation R2 -0.98987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  13%|█▎        | 16/120 [00:22<02:24,  1.39s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16: Training Loss 1.37512, Training R2 0.35743 Validation Loss 2.52653 Validation R2 -0.93686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  14%|█▍        | 17/120 [00:23<02:17,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17: Training Loss 1.40552, Training R2 0.32341 Validation Loss 2.51478 Validation R2 -0.9266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  15%|█▌        | 18/120 [00:24<02:12,  1.30s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18: Training Loss 1.38294, Training R2 0.33562 Validation Loss 2.51978 Validation R2 -0.9438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  16%|█▌        | 19/120 [00:26<02:07,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19: Training Loss 1.36854, Training R2 0.34694 Validation Loss 2.52149 Validation R2 -0.94904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  17%|█▋        | 20/120 [00:27<02:04,  1.24s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Training Loss 1.39516, Training R2 0.33172 Validation Loss 2.50493 Validation R2 -0.91365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 21/120 [00:28<02:01,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21: Training Loss 1.38629, Training R2 0.33781 Validation Loss 2.4711 Validation R2 -0.84151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  18%|█▊        | 22/120 [00:29<01:59,  1.22s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22: Training Loss 1.35907, Training R2 0.35832 Validation Loss 2.43337 Validation R2 -0.76061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  19%|█▉        | 23/120 [00:31<02:04,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23: Training Loss 1.36383, Training R2 0.35625 Validation Loss 2.4086 Validation R2 -0.70319\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  20%|██        | 24/120 [00:32<02:15,  1.41s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24: Training Loss 1.37217, Training R2 0.35485 Validation Loss 2.40206 Validation R2 -0.68041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  21%|██        | 25/120 [00:34<02:22,  1.50s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25: Training Loss 1.35882, Training R2 0.3699 Validation Loss 2.40313 Validation R2 -0.67688\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▏       | 26/120 [00:36<02:20,  1.49s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26: Training Loss 1.35912, Training R2 0.37495 Validation Loss 2.39532 Validation R2 -0.66552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  22%|██▎       | 27/120 [00:37<02:10,  1.40s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27: Training Loss 1.36786, Training R2 0.37135 Validation Loss 2.3691 Validation R2 -0.6297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  23%|██▎       | 28/120 [00:38<02:04,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28: Training Loss 1.35706, Training R2 0.37533 Validation Loss 2.32856 Validation R2 -0.5758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  24%|██▍       | 29/120 [00:40<02:07,  1.40s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29: Training Loss 1.34702, Training R2 0.37567 Validation Loss 2.28898 Validation R2 -0.52579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  25%|██▌       | 30/120 [00:41<02:10,  1.45s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30: Training Loss 1.35462, Training R2 0.36433 Validation Loss 2.26563 Validation R2 -0.4978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  26%|██▌       | 31/120 [00:42<02:01,  1.37s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31: Training Loss 1.35535, Training R2 0.36144 Validation Loss 2.26006 Validation R2 -0.49145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  27%|██▋       | 32/120 [00:43<01:56,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32: Training Loss 1.34697, Training R2 0.36851 Validation Loss 2.259 Validation R2 -0.48809\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 33/120 [00:45<01:52,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33: Training Loss 1.34989, Training R2 0.36989 Validation Loss 2.24688 Validation R2 -0.46614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  28%|██▊       | 34/120 [00:46<02:00,  1.40s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34: Training Loss 1.3532, Training R2 0.3693 Validation Loss 2.21798 Validation R2 -0.41891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  29%|██▉       | 35/120 [00:48<02:05,  1.47s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35: Training Loss 1.34537, Training R2 0.37407 Validation Loss 2.1798 Validation R2 -0.35923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  30%|███       | 36/120 [00:50<02:09,  1.54s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36: Training Loss 1.34303, Training R2 0.37492 Validation Loss 2.14551 Validation R2 -0.30603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  31%|███       | 37/120 [00:51<01:58,  1.43s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37: Training Loss 1.34925, Training R2 0.37059 Validation Loss 2.12353 Validation R2 -0.27025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▏      | 38/120 [00:52<01:52,  1.37s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38: Training Loss 1.34613, Training R2 0.37477 Validation Loss 2.11018 Validation R2 -0.24795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  32%|███▎      | 39/120 [00:54<01:54,  1.41s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39: Training Loss 1.34422, Training R2 0.37823 Validation Loss 2.09194 Validation R2 -0.22388\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  33%|███▎      | 40/120 [00:55<01:48,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 40: Training Loss 1.34613, Training R2 0.37871 Validation Loss 2.05641 Validation R2 -0.18402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  34%|███▍      | 41/120 [00:56<01:44,  1.32s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 41: Training Loss 1.34536, Training R2 0.37713 Validation Loss 2.00466 Validation R2 -0.13002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  35%|███▌      | 42/120 [00:57<01:40,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 42: Training Loss 1.34171, Training R2 0.37659 Validation Loss 1.94815 Validation R2 -0.07387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  36%|███▌      | 43/120 [00:59<01:37,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 43: Training Loss 1.34214, Training R2 0.37263 Validation Loss 1.90337 Validation R2 -0.02976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  37%|███▋      | 44/120 [01:00<01:38,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 44: Training Loss 1.34318, Training R2 0.37069 Validation Loss 1.87404 Validation R2 0.00102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  38%|███▊      | 45/120 [01:02<01:45,  1.41s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 45: Training Loss 1.34078, Training R2 0.37327 Validation Loss 1.85092 Validation R2 0.02717\n",
            "Epoch 46: Training Loss 1.34085, Training R2 0.37572 Validation Loss 1.81955 Validation R2 0.06022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  39%|███▉      | 47/120 [01:05<01:45,  1.44s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 47: Training Loss 1.34143, Training R2 0.37631 Validation Loss 1.7745 Validation R2 0.10264\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  40%|████      | 48/120 [01:06<01:39,  1.38s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 48: Training Loss 1.33968, Training R2 0.37819 Validation Loss 1.72229 Validation R2 0.14703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  41%|████      | 49/120 [01:07<01:34,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 49: Training Loss 1.33914, Training R2 0.37794 Validation Loss 1.67889 Validation R2 0.18194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  42%|████▏     | 50/120 [01:08<01:31,  1.30s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50: Training Loss 1.33909, Training R2 0.37796 Validation Loss 1.65098 Validation R2 0.20439\n",
            "Epoch 51: Training Loss 1.33815, Training R2 0.38031 Validation Loss 1.63118 Validation R2 0.21941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  43%|████▎     | 52/120 [01:11<01:37,  1.43s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 52: Training Loss 1.33808, Training R2 0.38138 Validation Loss 1.60627 Validation R2 0.2346\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  44%|████▍     | 53/120 [01:12<01:31,  1.36s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 53: Training Loss 1.33871, Training R2 0.38106 Validation Loss 1.56938 Validation R2 0.25392\n",
            "Epoch 54: Training Loss 1.33667, Training R2 0.38009 Validation Loss 1.52722 Validation R2 0.27451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  46%|████▌     | 55/120 [01:15<01:34,  1.45s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 55: Training Loss 1.33646, Training R2 0.37857 Validation Loss 1.49395 Validation R2 0.29063\n",
            "Epoch 56: Training Loss 1.33714, Training R2 0.37657 Validation Loss 1.47402 Validation R2 0.3012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  48%|████▊     | 57/120 [01:19<01:36,  1.54s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 57: Training Loss 1.3368, Training R2 0.37623 Validation Loss 1.46262 Validation R2 0.30859\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  48%|████▊     | 58/120 [01:20<01:29,  1.45s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 58: Training Loss 1.33615, Training R2 0.37773 Validation Loss 1.45021 Validation R2 0.31682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  49%|████▉     | 59/120 [01:21<01:23,  1.37s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59: Training Loss 1.33672, Training R2 0.3783 Validation Loss 1.43247 Validation R2 0.3273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  50%|█████     | 60/120 [01:22<01:20,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 60: Training Loss 1.33511, Training R2 0.37892 Validation Loss 1.41348 Validation R2 0.33803\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  51%|█████     | 61/120 [01:24<01:17,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 61: Training Loss 1.33474, Training R2 0.37922 Validation Loss 1.39894 Validation R2 0.34646\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▏    | 62/120 [01:25<01:14,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 62: Training Loss 1.33574, Training R2 0.37846 Validation Loss 1.3907 Validation R2 0.35192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  52%|█████▎    | 63/120 [01:26<01:11,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 63: Training Loss 1.33436, Training R2 0.3802 Validation Loss 1.3848 Validation R2 0.35564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  53%|█████▎    | 64/120 [01:27<01:10,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 64: Training Loss 1.33469, Training R2 0.38084 Validation Loss 1.37742 Validation R2 0.35894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  54%|█████▍    | 65/120 [01:29<01:10,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 65: Training Loss 1.33499, Training R2 0.38018 Validation Loss 1.36782 Validation R2 0.36243\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  55%|█████▌    | 66/120 [01:30<01:16,  1.41s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 66: Training Loss 1.33435, Training R2 0.37968 Validation Loss 1.35864 Validation R2 0.3656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  56%|█████▌    | 67/120 [01:32<01:19,  1.51s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 67: Training Loss 1.3339, Training R2 0.37844 Validation Loss 1.35226 Validation R2 0.36836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▋    | 68/120 [01:34<01:15,  1.46s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 68: Training Loss 1.33374, Training R2 0.37824 Validation Loss 1.34844 Validation R2 0.37107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  57%|█████▊    | 69/120 [01:35<01:10,  1.38s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 69: Training Loss 1.33325, Training R2 0.37909 Validation Loss 1.34589 Validation R2 0.37374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  58%|█████▊    | 70/120 [01:36<01:06,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 70: Training Loss 1.33329, Training R2 0.37985 Validation Loss 1.34355 Validation R2 0.37593\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  59%|█████▉    | 71/120 [01:37<01:04,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 71: Training Loss 1.33218, Training R2 0.38138 Validation Loss 1.34129 Validation R2 0.37744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  60%|██████    | 72/120 [01:38<01:01,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 72: Training Loss 1.33252, Training R2 0.38111 Validation Loss 1.33928 Validation R2 0.3782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  61%|██████    | 73/120 [01:40<00:59,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 73: Training Loss 1.33208, Training R2 0.38141 Validation Loss 1.33751 Validation R2 0.37881\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▏   | 74/120 [01:41<00:58,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 74: Training Loss 1.33259, Training R2 0.38073 Validation Loss 1.33567 Validation R2 0.37939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  62%|██████▎   | 75/120 [01:42<00:55,  1.24s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 75: Training Loss 1.33152, Training R2 0.38164 Validation Loss 1.33405 Validation R2 0.37958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  63%|██████▎   | 76/120 [01:44<00:59,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 76: Training Loss 1.3311, Training R2 0.38146 Validation Loss 1.3331 Validation R2 0.37901\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  64%|██████▍   | 77/120 [01:45<01:02,  1.46s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 77: Training Loss 1.33179, Training R2 0.38034 Validation Loss 1.33288 Validation R2 0.37811\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  65%|██████▌   | 78/120 [01:47<01:05,  1.57s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 78: Training Loss 1.3315, Training R2 0.38063 Validation Loss 1.3329 Validation R2 0.37782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  66%|██████▌   | 79/120 [01:48<01:00,  1.47s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 79: Training Loss 1.33127, Training R2 0.38002 Validation Loss 1.33289 Validation R2 0.37823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  67%|██████▋   | 80/120 [01:50<00:56,  1.40s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 80: Training Loss 1.3305, Training R2 0.38062 Validation Loss 1.3332 Validation R2 0.37861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 81/120 [01:51<00:52,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 81: Training Loss 1.33076, Training R2 0.38109 Validation Loss 1.33375 Validation R2 0.3786\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  68%|██████▊   | 82/120 [01:52<00:49,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 82: Training Loss 1.33115, Training R2 0.38082 Validation Loss 1.33436 Validation R2 0.37816\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  69%|██████▉   | 83/120 [01:53<00:46,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 83: Training Loss 1.33075, Training R2 0.38113 Validation Loss 1.33436 Validation R2 0.37808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  70%|███████   | 84/120 [01:55<00:45,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 84: Training Loss 1.32925, Training R2 0.38173 Validation Loss 1.33375 Validation R2 0.37826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  71%|███████   | 85/120 [01:56<00:43,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 85: Training Loss 1.32988, Training R2 0.38124 Validation Loss 1.33287 Validation R2 0.37845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▏  | 86/120 [01:57<00:42,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 86: Training Loss 1.33009, Training R2 0.38121 Validation Loss 1.33225 Validation R2 0.37838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  72%|███████▎  | 87/120 [01:59<00:44,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 87: Training Loss 1.32948, Training R2 0.38143 Validation Loss 1.33205 Validation R2 0.37801\n",
            "Epoch 88: Training Loss 1.32939, Training R2 0.38109 Validation Loss 1.33224 Validation R2 0.37762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  74%|███████▍  | 89/120 [02:02<00:48,  1.55s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 89: Training Loss 1.32959, Training R2 0.38063 Validation Loss 1.33181 Validation R2 0.37832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  75%|███████▌  | 90/120 [02:03<00:43,  1.46s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 90: Training Loss 1.32824, Training R2 0.38144 Validation Loss 1.33117 Validation R2 0.37935\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  76%|███████▌  | 91/120 [02:05<00:40,  1.38s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 91: Training Loss 1.32788, Training R2 0.38212 Validation Loss 1.33135 Validation R2 0.37939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  77%|███████▋  | 92/120 [02:06<00:37,  1.34s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 92: Training Loss 1.32805, Training R2 0.38228 Validation Loss 1.33251 Validation R2 0.37822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 93/120 [02:07<00:35,  1.30s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 93: Training Loss 1.32823, Training R2 0.38191 Validation Loss 1.33276 Validation R2 0.37789\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  78%|███████▊  | 94/120 [02:08<00:33,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 94: Training Loss 1.32696, Training R2 0.38228 Validation Loss 1.33174 Validation R2 0.37874\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  79%|███████▉  | 95/120 [02:10<00:31,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 95: Training Loss 1.32771, Training R2 0.38188 Validation Loss 1.33108 Validation R2 0.37917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  80%|████████  | 96/120 [02:11<00:30,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 96: Training Loss 1.3275, Training R2 0.38219 Validation Loss 1.33146 Validation R2 0.3784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  81%|████████  | 97/120 [02:12<00:28,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 97: Training Loss 1.32699, Training R2 0.38201 Validation Loss 1.33233 Validation R2 0.37727\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▏ | 98/120 [02:14<00:30,  1.38s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 98: Training Loss 1.32697, Training R2 0.38157 Validation Loss 1.33152 Validation R2 0.37813\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  82%|████████▎ | 99/120 [02:15<00:30,  1.47s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 99: Training Loss 1.32656, Training R2 0.38212 Validation Loss 1.33031 Validation R2 0.37944\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  83%|████████▎ | 100/120 [02:17<00:31,  1.55s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 100: Training Loss 1.32581, Training R2 0.38318 Validation Loss 1.33074 Validation R2 0.37889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  84%|████████▍ | 101/120 [02:18<00:27,  1.44s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 101: Training Loss 1.32647, Training R2 0.3825 Validation Loss 1.33174 Validation R2 0.37766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  85%|████████▌ | 102/120 [02:20<00:24,  1.38s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 102: Training Loss 1.32615, Training R2 0.38214 Validation Loss 1.3313 Validation R2 0.37785\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  86%|████████▌ | 103/120 [02:21<00:22,  1.33s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 103: Training Loss 1.3257, Training R2 0.3824 Validation Loss 1.33028 Validation R2 0.37863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  87%|████████▋ | 104/120 [02:22<00:21,  1.32s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 104: Training Loss 1.32565, Training R2 0.38263 Validation Loss 1.33047 Validation R2 0.37815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 105/120 [02:23<00:19,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 105: Training Loss 1.32557, Training R2 0.38243 Validation Loss 1.33143 Validation R2 0.37686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  88%|████████▊ | 106/120 [02:24<00:17,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 106: Training Loss 1.32563, Training R2 0.38164 Validation Loss 1.33144 Validation R2 0.37683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  89%|████████▉ | 107/120 [02:26<00:16,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 107: Training Loss 1.32497, Training R2 0.38219 Validation Loss 1.33075 Validation R2 0.37762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  90%|█████████ | 108/120 [02:27<00:15,  1.25s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 108: Training Loss 1.32517, Training R2 0.38227 Validation Loss 1.33111 Validation R2 0.37719\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  91%|█████████ | 109/120 [02:29<00:15,  1.37s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 109: Training Loss 1.32593, Training R2 0.38188 Validation Loss 1.33125 Validation R2 0.37697\n",
            "Epoch 110: Training Loss 1.32551, Training R2 0.38159 Validation Loss 1.33099 Validation R2 0.37716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:  92%|█████████▎| 111/120 [02:32<00:13,  1.51s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 111: Training Loss 1.32468, Training R2 0.38213 Validation Loss 1.33104 Validation R2 0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  93%|█████████▎| 112/120 [02:33<00:11,  1.43s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 112: Training Loss 1.32529, Training R2 0.38194 Validation Loss 1.33079 Validation R2 0.377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  94%|█████████▍| 113/120 [02:34<00:09,  1.35s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 113: Training Loss 1.32497, Training R2 0.38206 Validation Loss 1.33061 Validation R2 0.37691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  95%|█████████▌| 114/120 [02:36<00:07,  1.31s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 114: Training Loss 1.32524, Training R2 0.38156 Validation Loss 1.33043 Validation R2 0.37673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  96%|█████████▌| 115/120 [02:37<00:06,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 115: Training Loss 1.32415, Training R2 0.38209 Validation Loss 1.33075 Validation R2 0.37611\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  97%|█████████▋| 116/120 [02:38<00:05,  1.28s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 116: Training Loss 1.32388, Training R2 0.38184 Validation Loss 1.33082 Validation R2 0.3759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 117/120 [02:39<00:03,  1.26s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 117: Training Loss 1.32389, Training R2 0.38164 Validation Loss 1.33034 Validation R2 0.37644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  98%|█████████▊| 118/120 [02:41<00:02,  1.27s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 118: Training Loss 1.32354, Training R2 0.38197 Validation Loss 1.3309 Validation R2 0.37577\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:  99%|█████████▉| 119/120 [02:42<00:01,  1.29s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 119: Training Loss 1.32304, Training R2 0.38177 Validation Loss 1.33083 Validation R2 0.37567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining: 100%|██████████| 120/120 [02:44<00:00,  1.43s/Epochs]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 120: Training Loss 1.32323, Training R2 0.38234 Validation Loss 1.33032 Validation R2 0.37596\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining: 100%|██████████| 120/120 [02:44<00:00,  1.37s/Epochs]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Model Predictions for Model Type GraphSage\n",
            "Minimum validation loss: 1.3302770853042603\n",
            "Minimum test loss: 1.3257473707199097\n",
            "Minimum test R2: 0.38216400146484375\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACAT0lEQVR4nO3dd3xT1RvH8c9N0qa7pVBogVKmZSN7yZKNLAVUQIGfgIpMFUVcIIIogsoQN+BAUWQpsvfeQ2ZZhSJ7do+M8/ujbWjooIW2aenz9pWX5OYm97k3afPtueecqymlFEIIIYQQDqJzdAFCCCGEKNgkjAghhBDCoSSMCCGEEMKhJIwIIYQQwqEkjAghhBDCoSSMCCGEEMKhJIwIIYQQwqEkjAghhBDCoSSMCCGEEMKhJIyIPE3TNMaOHevoMlKZM2cOmqZx9uxZR5eSprxeX27ZsGEDmqaxYcMG27J+/fpRunTpbNuGHGshHpyEEZHjkn9Za5rGli1bUj2ulCIwMBBN0+jYsaMDKkzfRx99xOLFix1dhp3SpUvbjufdt7i4OEeXZ6d58+Z29fn6+lK3bl1mzZqF1Wp1dHlZklc/C/f6mQkJCeHVV1+lUaNGuLi4ZDk4NW/enKpVqz5gpUJkzODoAkTB4eLiwq+//spjjz1mt3zjxo38999/GI3GVM+JjY3FYHDcx/Sjjz6ie/fudO3a1W75888/z7PPPptmzbnh0Ucf5fXXX0+13NnZ2QHVZKxkyZJMnDgRgGvXrvHTTz/Rv39/Tpw4wccff5zr9Xz33Xf3FYTy6mfhXrZv3860adOoXLkylSpV4sCBA44uSYhUJIyIXNOhQwfmz5/PtGnT7ALGr7/+Su3atbl+/Xqq57i4uGTb9q1WKwkJCdnymnq9Hr1enw1V3Z8SJUrw3HPPOWz7WeHt7W1X60svvURwcDAzZszgww8/xMnJKdVzsvO9ulta23sQjv4s3Evnzp25ffs2np6eTJ48WcKIyJPkNI3INT179uTGjRusXr3atiwhIYE///yTXr16pfmctPqMbNiwgTp16uDi4kK5cuX45ptvGDt2LJqmpXrukCFDmDt3LlWqVMFoNLJixQoAJk+eTKNGjShcuDCurq7Url2bP//8M9Xzo6Oj+fHHH22nGfr16wek309g5syZtm0VL16cwYMHc/v2bbt1kpu9jx49SosWLXBzc6NEiRJMmjQpk0fy/t2rvmnTpqHX6+2WTZkyBU3TeO2112zLLBYLnp6ejBo1Kss1uLm50aBBA6Kjo7l27RqQ8Xt14cIFXnjhBYoVK4bRaKRKlSrMmjUr1ev+999/dO3aFXd3d4oWLcqrr75KfHx8qvXS6jNitVqZOnUq1apVw8XFBT8/P9q1a8eePXts9eXXz4Kvry+enp7Z9nrpycz+njx5km7duuHv74+LiwslS5bk2WefJTw83LbO6tWreeyxx/Dx8cHDw4Pg4GDefvvtHK9fOJa0jIhcU7p0aRo2bMhvv/1G+/btAVi+fDnh4eE8++yzTJs27Z6vsX//ftq1a0dAQAAffPABFouFcePG4efnl+b669at448//mDIkCEUKVLE9iU0depUOnfuTO/evUlISGDevHn06NGDpUuX8sQTTwDw888/M2DAAOrVq8eLL74IQLly5dKtbezYsXzwwQe0atWKQYMGERISwldffcXu3bvZunWr3V/kt27dol27djz11FM8/fTT/Pnnn4waNYpq1arZjk1GTCZTqpYkNzc33NzcHqi+Jk2aYLVa2bJli60vwubNm9HpdGzevNn2Wvv37ycqKoqmTZves9a0nDlzBr1ej4+Pj21ZWu/VlStXaNCggS2s+Pn5sXz5cvr3709ERAQjRowAEk/ntWzZkrCwMIYNG0bx4sX5+eefWbduXabq6d+/P3PmzKF9+/YMGDAAs9nM5s2b2bFjB3Xq1MnTn4W8IDP7m5CQQNu2bYmPj2fo0KH4+/tz4cIFli5dyu3bt/H29ubIkSN07NiR6tWrM27cOIxGI6dOnWLr1q2O3kWR05QQOWz27NkKULt371YzZsxQnp6eKiYmRimlVI8ePVSLFi2UUkoFBQWpJ554wu65gBozZoztfqdOnZSbm5u6cOGCbdnJkyeVwWBQd3+cAaXT6dSRI0dS1ZS8/WQJCQmqatWq6vHHH7db7u7urvr27ZvuPoWGhiqllLp69apydnZWbdq0URaLxbbejBkzFKBmzZplW9asWTMFqJ9++sm2LD4+Xvn7+6tu3bql2tbdgoKCFJDqlvI43W99FotFeXl5qTfffFMppZTValWFCxdWPXr0UHq9XkVGRiqllPrss8+UTqdTt27dyrDWZs2aqYoVK6pr166pa9euqWPHjqlhw4YpQHXq1Mm2XnrvVf/+/VVAQIC6fv263fJnn31WeXt7297HL774QgHqjz/+sK0THR2typcvrwC1fv162/K+ffuqoKAg2/1169YpQA0bNixV/Var1fbvvPpZuPtnJiOffvqpXa2Z0axZM1WlSpV0H8/s/u7fv18Bav78+em+1ueff64Ade3atUzXJx4OcppG5Kqnn36a2NhYli5dSmRkJEuXLk33FM3dLBYLa9asoWvXrhQvXty2vHz58un+BdmsWTMqV66carmrq6vt37du3SI8PJwmTZqwb9++LO5RojVr1pCQkMCIESPQ6e78WA0cOBAvLy/++ecfu/U9PDzs+lE4OztTr149zpw5k6nt1a9fn9WrV9vd+vTp88D16XQ6GjVqxKZNmwA4duwYN27c4K233kIpxfbt24HE1pKqVavatWyk5/jx4/j5+eHn50elSpWYPn06TzzxRKpTLXe/V0opFixYQKdOnVBKcf36ddutbdu2hIeH296vZcuWERAQQPfu3W3Pd3Nzs7ViZGTBggVomsaYMWNSPXb3qb/MyO3PgqNldn+9vb0BWLlyJTExMWm+VvLnacmSJflutJV4MHKaRuQqPz8/WrVqxa+//kpMTAwWi8XuCyQjV69eJTY2lvLly6d6LK1lAGXKlElz+dKlSxk/fjwHDhyw61dwP18+AOfOnQMgODjYbrmzszNly5a1PZ6sZMmSqbZVqFAh/v3330xtr0iRIrRq1SpH6mvSpAljx44lNjaWzZs3ExAQQK1atahRowabN2+mdevWbNmyhaeffjpT2y5dujTfffcdmqbh4uJChQoVKFq0aKr17n6vrl27xu3bt/n222/59ttv03ztq1ev2vavfPnyqY7p3fubltOnT1O8eHF8fX0ztT/3ktufBUfL7P6WKVOG1157jc8++4y5c+fSpEkTOnfuzHPPPWcLKs888wzff/89AwYM4K233qJly5Y89dRTdO/e3S7oiIePhBGR63r16sXAgQO5fPky7du3z9Rf1/crZQtIss2bN9O5c2eaNm3KzJkzCQgIwMnJidmzZ/Prr7/mWC0ppTf6QimVK9vPyGOPPYbJZGL79u1s3ryZJk2aAIkhZfPmzRw/fpxr167Zlt+Lu7t7poLT3e9V8l/Gzz33HH379k3zOdWrV89UDXlZXv4sZLcpU6bQr18/lixZwqpVqxg2bBgTJ05kx44dlCxZEldXVzZt2sT69ev5559/WLFiBb///juPP/44q1atytOjlsSDkagpct2TTz6JTqdjx44dmT5FA1C0aFFcXFw4depUqsfSWpaeBQsW4OLiwsqVK3nhhRdo3759ul+WmW0pCQoKAhInmEopISGB0NBQ2+OOkpX66tWrh7OzM5s3b7YLI02bNmXnzp2sXbvWdj8n+fn54enpicVioVWrVmnekltYgoKCOH36dKov8Lv3Ny3lypXj4sWL3Lx5M8P1HpbPQnbL6v5Wq1aNd999l02bNrF582YuXLjA119/bXtcp9PRsmVLPvvsM44ePcqECRNYt24d69evz/mdEQ4jYUTkOg8PD7766ivGjh1Lp06dMv08vV5Pq1atWLx4MRcvXrQtP3XqFMuXL8/S62iahsVisS07e/ZsmrNruru7pxqemJZWrVrh7OzMtGnT7L4Qf/jhB8LDw20jdBwlK/W5uLhQt25dfvvtN8LCwuxaRmJjY5k2bRrlypUjICAgR2vW6/V069aNBQsWcPjw4VSPJw8LhsQ5bC5evGg3PDsmJibd0zspdevWDaUUH3zwQarHUh6rh+WzkN0yu78RERGYzWa751arVg2dTmc7VZpWIHz00UcB0hymLR4ecppGOER6ze73MnbsWFatWkXjxo0ZNGgQFouFGTNmULVq1UxP5vTEE0/w2Wef0a5dO3r16sXVq1f58ssvKV++fKrz9LVr12bNmjV89tlnFC9enDJlylC/fv1Ur+nn58fo0aP54IMPaNeuHZ07dyYkJISZM2dSt25dh09QltX6mjRpwscff4y3tzfVqlUDElumgoODCQkJsc2xkdM+/vhj1q9fT/369Rk4cCCVK1fm5s2b7Nu3jzVr1ti+vAYOHMiMGTPo06cPe/fuJSAggJ9//jnDoc7JWrRowfPPP8+0adM4efIk7dq1w2q1snnzZlq0aMGQIUOAvPtZOHXqFOPHj0+1vGbNmjzxxBOEh4czffp0ANsQ2RkzZuDj44OPj49t/zJy7dq1NLdRpkwZevfunan9XbduHUOGDKFHjx488sgjmM1mfv75Z1voBBg3bhybNm3iiSeeICgoiKtXrzJz5kxKliyZauZm8ZBxzCAeUZCkHNqbkcwM7VVKqbVr16qaNWsqZ2dnVa5cOfX999+r119/Xbm4uKR67uDBg9Pc1g8//KAqVKigjEajqlixopo9e7YaM2ZMquHBx48fV02bNlWurq4KsA3tvHs4Z7IZM2aoihUrKicnJ1WsWDE1aNCgVMNf0xsqefeQ0/RkZjjng9SnlFL//POPAlT79u3tlg8YMEAB6ocffrhnnUrde1hosozeqytXrqjBgwerwMBA5eTkpPz9/VXLli3Vt99+a7feuXPnVOfOnZWbm5sqUqSIGj58uFqxYsU9h/YqpZTZbFaffvqpqlixonJ2dlZ+fn6qffv2au/evbZ18upngTSGeQOqf//+SimlQkND010nM9tIHn6c1q1ly5aZ3t8zZ86oF154QZUrV065uLgoX19f1aJFC7VmzRrbOmvXrlVdunRRxYsXV87Ozqp48eKqZ8+e6sSJE/esU+RvmlIPYS8pUeB07dqVI0eOcPLkSUeXIoQQIoukz4jId2JjY+3unzx5kmXLltG8eXPHFCSEEOKBSMuIyHcCAgLo16+fbQ6Dr776ivj4ePbv30+FChUcXZ4QQogskg6sIt9p164dv/32G5cvX8ZoNNKwYUM++ugjCSJCCJFPScuIEEIIIRxK+owIIYQQwqEkjAghhBDCofJFnxGr1crFixfx9PS87wuZCSGEECJ3KaWIjIykePHiGV7sMF+EkYsXLxIYGOjoMoQQQghxH86fP0/JkiXTfTxfhBFPT08gcWe8vLwcXI0QQgghMiMiIoLAwEDb93h68kUYST414+XlJWFECCGEyGfu1cVCOrAKIYQQwqEkjAghhBDCoSSMCCGEEMKh8kWfESHEw08phdlsxmKxOLoUIUQm6fV6DAbDA0+7IWFECOFwCQkJXLp0iZiYGEeXIoTIIjc3NwICAnB2dr7v15AwIoRwKKvVSmhoKHq9nuLFi+Ps7CyTGwqRDyilSEhI4Nq1a4SGhlKhQoUMJzbLiIQRIYRDJSQkYLVaCQwMxM3NzdHlCCGywNXVFScnJ86dO0dCQgIuLi739TrSgVUIkSfc719UQgjHyo6fXfnpF0IIIYRDSRgRQgghhENJGBFCiDygdOnSfPHFF5lef8OGDWiaxu3bt3OsJoA5c+bg4+OTo9t4GJw9exZN0zhw4ICjS8mXJIwIIcR9aN68OSNGjMi219u9ezcvvvhiptdv1KgRly5dwtvbO9tqyM/Wr19Px44d8fPzw8XFhXLlyvHMM8+wadMmR5dm57vvvqNGjRp4eHjg4+NDzZo1mThxoqPLcjgJIymsP36VJQcuOLoMIcRDInkit8zw8/PL0mgiZ2dn/P39ZRg0MHPmTFq2bEnhwoX5/fffCQkJYdGiRTRq1IhXX3013edZLBasVmuu1Tlr1ixGjBjBsGHDOHDgAFu3buXNN98kKioq12rIs1Q+EB4ergAVHh6eo9up8v4KVeatpep2dEKObkcIcUdsbKw6evSoio2NVUopZbVaVXS8ySE3q9WaqZr79u2rALtbaGioWr9+vQLUsmXLVK1atZSTk5Nav369OnXqlOrcubMqWrSocnd3V3Xq1FGrV6+2e82goCD1+eef2+4D6rvvvlNdu3ZVrq6uqnz58mrJkiW2x5O3devWLaWUUrNnz1be3t5qxYoVqmLFisrd3V21bdtWXbx40fYck8mkhg4dqry9vZWvr6968803VZ8+fVSXLl3S3dfk101p5syZqmzZssrJyUk98sgj6qeffrI9ZrVa1ZgxY1RgYKBydnZWAQEBaujQobbHv/zyS1W+fHllNBpV0aJFVbdu3TJ1zNNz7tw55eTkpF599dU0H0/5nibvy5IlS1SlSpWUXq9XoaGhateuXapVq1aqcOHCysvLSzVt2lTt3bvX7nUANXPmTNWuXTvl4uKiypQpo+bPn297PDQ0VAFqwYIFqnnz5srV1VVVr15dbdu2zbZOly5dVL9+/TLcn8zUcuzYMdW4cWNlNBpVpUqV1OrVqxWgFi1aZFsnLCxM9ejRQ3l7e6tChQqpzp07q9DQ0Hsdzvty989wSpn9/pZ5RpKYLVai4hP/golOMOPt5uTgioQomGJNFiq/v9Ih2z46ri1uzvf+tTh16lROnDhB1apVGTduHJDYsnH27FkA3nrrLSZPnkzZsmUpVKgQ58+fp0OHDkyYMAGj0chPP/1Ep06dCAkJoVSpUulu54MPPmDSpEl8+umnTJ8+nd69e3Pu3Dl8fX3TXD8mJobJkyfz888/o9PpeO655xg5ciRz584F4JNPPmHu3LnMnj2bSpUqMXXqVBYvXkyLFi0yfYwWLVrE8OHD+eKLL2jVqhVLly7lf//7HyVLlqRFixYsWLCAzz//nHnz5lGlShUuX77MwYMHAdizZw/Dhg3j559/plGjRty8eZPNmzdnettpWbBgASaTiTfffDPNx+9uOYqJieGTTz7h+++/p3DhwhQtWpQzZ87Qt29fpk+fjlKKKVOm0KFDB06ePImnp6ftue+99x4ff/wxU6dO5eeff+bZZ5/l0KFDVKpUybbOO++8w+TJk6lQoQLvvPMOPXv25NSpUxgMBvz9/dm4cSPnzp0jKCgozXojIyMzrMVisdC1a1dKlSrFzp07iYyM5PXXX7d7DZPJRNu2bWnYsCGbN2/GYDAwfvx42rVrx7///vtAM6XmFAkjSeLNd5rqLFblwEqEEHmdt7c3zs7OuLm54e/vn+rxcePG0bp1a9t9X19fatSoYbv/4YcfsmjRIv766y+GDBmS7nb69etHz549Afjoo4+YNm0au3btol27dmmubzKZ+PrrrylXrhwAQ4YMsYUlgOnTpzN69GiefPJJAGbMmMGyZcuysOcwefJk+vXrxyuvvALAa6+9xo4dO5g8eTItWrQgLCwMf39/WrVqhZOTE6VKlaJevXoAhIWF4e7uTseOHfH09CQoKIiaNWtmaft3O3HiBF5eXnbvw4IFC+jbt6/t/vbt26lWrRqQeIxmzpxp9348/vjjdq/57bff4uPjw8aNG+nYsaNteY8ePRgwYACQ+B6uXr2a6dOnM3PmTNs6I0eO5IknngASw2SVKlU4deoUFStWZMyYMTz11FOULl2aRx55hIYNG9KhQwe6d+9um6vjXrWsXr2a06dPs2HDBts+T5gwwe7z9vvvv2O1Wvn+++9tYWz27Nn4+PiwYcMG2rRpk9XDnOMkjCRJkDAiRJ7g6qTn6Li2Dtt2dqhTp47d/aioKMaOHcs///zDpUuXMJvNxMbGEhYWluHrVK9e3fZvd3d3vLy8uHr1arrru7m52YIIQEBAgG398PBwrly5YgsGkHiRs9q1a2ep38SxY8dSdbRt3LgxU6dOBRK/sL/44gvKli1Lu3bt6NChA506dcJgMNC6dWuCgoJsj7Vr144nn3wy3b4yHh4etn8/99xzfP3112mud3frR9u2bTlw4AAXLlygefPmdhdfdHZ2tjuuAFeuXOHdd99lw4YNXL16FYvFQkxMTKr3p2HDhqnu3z16JuVrBwQEAHD16lUqVqxIQEAA27dv5/Dhw2zatIlt27bRt29fvv/+e1asWIFOp7tnLSEhIQQGBtqFr5TvKcDBgwc5deqUXasOQFxcHKdPn07zGDqahJEkCZY7P4xmCSNCOIymaZk6VZKXubu7290fOXIkq1evZvLkyZQvXx5XV1e6d+9OQkJChq/j5GR/uljTtAyDQ1rrK5W7v88CAwMJCQlhzZo1rF69mldeeYVPP/2UjRs34unpyb59+9iwYQOrVq3i/fffZ+zYsezevTvN4cMpv+i9vLzS3F6FChUIDw/n8uXLti9oDw8Pypcvj8GQ+nPk6uqaKrz07duXGzduMHXqVIKCgjAajTRs2PCe709aUr4Hydu5+z2rWrUqVatW5ZVXXuHll1+mSZMmbNy4kRYtWmRLLVFRUdSuXdt2ei4lPz+/LO9TbpDRNEmkZUQIkRXOzs52f3FnZOvWrfTr148nn3ySatWq4e/vb+tfklu8vb0pVqwYu3fvti2zWCzs27cvS69TqVIltm7dards69atVK5c2Xbf1dWVTp06MW3aNDZs2MD27ds5dOgQAAaDgVatWjFp0iT+/fdfzp49y7p169LcVvny5W23okWLprlO9+7dcXJy4pNPPsnSftxd/7Bhw+jQoQNVqlTBaDRy/fr1VOvt2LEj1f2U/UXuR/Jxi46OzlQtwcHBnD9/nitXrtiWpXxPAWrVqsXJkycpWrSo3TEsX758nh0Knr///MhGKfuMmHNxqJcQIn8qXbo0O3fu5OzZs3h4eKTbqRQS/3pfuHAhnTp1QtM03nvvvVwdUpps6NChTJw4kfLly1OxYkWmT5/OrVu3sjQ8+I033uDpp5+mZs2atGrVir///puFCxeyZs0aIHGSNIvFQv369XFzc+OXX37B1dWVoKAgli5dypkzZ2jatCmFChVi2bJlWK1WgoOD73ufSpUqxZQpUxg+fDg3b96kX79+lClThps3b/LLL78AiaejMlKhQgV+/vln6tSpQ0REBG+88Qaurq6p1ps/fz516tThscceY+7cuezatYsffvgh07UOGjSI4sWL8/jjj1OyZEkuXbrE+PHj8fPzs50CulctrVu3ply5cvTt25dJkyYRGRnJu+++C9xpienduzeffvopXbp0Ydy4cZQsWZJz586xcOFC3nzzTUqWLJnpmnOLtIwkiTff+QtHWkaEEPcycuRI9Ho9lStXxs/PL8P+H5999hmFChWiUaNGdOrUibZt21KrVq1crDbRqFGj6NmzJ3369KFhw4Z4eHjQtm3bLF1ptWvXrkydOpXJkydTpUoVvvnmG2bPnk3z5s0B8PHx4bvvvqNx48ZUr16dNWvW8Pfff1O4cGF8fHxYuHAhjz/+OJUqVeLrr7/mt99+o0qVKg+0X0OHDmXVqlVcu3aN7t27U6FCBTp06EBoaCgrVqywdV5Nzw8//MCtW7eoVasWzz//PMOGDUuzJeaDDz5g3rx5VK9enZ9++onffvvNrkXoXlq1asWOHTvo0aMHjzzyCN26dcPFxYW1a9dSuHDhTNWi1+tZvHgxUVFR1K1blwEDBvDOO+8A2N5HNzc3Nm3aRKlSpXjqqaeoVKkS/fv3Jy4uLt3TXY6mqdw+oXgfIiIi8Pb2Jjw8PMcO5P6wWzw5cxsAi15pRM1ShXJkO0IIe3FxcYSGhlKmTJn7vvy4uD9Wq5VKlSrx9NNP8+GHHzq6nDxN0zQWLVpE165dHV1KKlu3buWxxx7j1KlTdh2Yc0tGP8OZ/f6W0zRJpM+IEOJhd+7cOVatWkWzZs2Ij49nxowZhIaG0qtXL0eXJrJg0aJFeHh4UKFCBU6dOsXw4cNp3LixQ4JIdpEwkkRG0wghHnY6nY45c+YwcuRIlFJUrVqVNWvWPHAnTJG7IiMjGTVqFGFhYRQpUoRWrVoxZcoUR5f1QCSMJJGWESHEwy4wMDDVSBiROXmpR0OfPn3o06ePo8vIVtKBNYn9aJq886ETQgghHnYSRpLYt4zI0F4hhBAit0gYSZIyjJgt0jIihBBC5BYJI0niU3Rgteahc4NCCCHEw07CSJIE6TMihBBCOISEkSQymkYIIYRwDAkjSVJOBy99RoQQuaF06dJ88cUXtvuaprF48eJ01z979iyapqW6bH1WZdfr3Eu/fv3y5Iylec2cOXPSvGpxQSJhJIm0jAghHO3SpUu0b98+W18zrUAQGBjIpUuXqFq1arZuKz9SSvHdd9/RsGFDvLy88PDwoEqVKgwfPpxTp045ujybmJgYRo8eTbly5XBxccHPz49mzZqxZMkSR5eWLSSMJJE+I0IIR/P398doNOb4dvR6Pf7+/hgMBXveS6UUvXr1YtiwYXTo0IFVq1Zx9OhRfvjhB1xcXBg/fny6z01ISMjFSuHll19m4cKFTJ8+nePHj7NixQq6d+/OjRs3crWOnCJhJEnK6eAtMppGCMdRChKiHXPL5M/+t99+S/HixbHeNSdRly5deOGFFwA4ffo0Xbp0oVixYnh4eFC3bl3WrFmT4evefZpm165d1KxZExcXF+rUqcP+/fvt1rdYLPTv358yZcrg6upKcHAwU6dOtT0+duxYfvzxR5YsWYKmaWiaxoYNG9I8TbNx40bq1auH0WgkICCAt956C7PZbHu8efPmDBs2jDfffBNfX1/8/f0ZO3Zspo5Xsvj4eNtVaF1cXHjsscfYvXu37fFbt27Ru3dv/Pz8cHV1pUKFCsyePRtI/PIfMmQIAQEBuLi4EBQUxMSJE7O0/bv9/vvvzJs3j99//5333nuPBg0aUKpUKRo0aMAnn3xi2zbcaWGaMGECxYsXJzg4GICff/6ZOnXq4Onpib+/P7169eLq1au2523YsAFN0/jnn3+oXr06Li4uNGjQgMOHD6eqZ+XKlVSqVAkPDw/atWvHpUuXbI/99ddfvP3223To0IHSpUtTu3Zthg4davu8ZaaW5NepUKECLi4utGjRgh9//BFN07h9+7ZtnS1bttCkSRNcXV0JDAxk2LBhREdHP9CxvpeCHYtTsDtNY5FJz4RwGFMMfFTcMdt++yI4u99ztR49ejB06FDWr19Py5YtAbh58yYrVqxg2bJlAERFRdGhQwcmTJiA0Wjkp59+olOnToSEhFCqVKl7biMqKoqOHTvSunVrfvnlF0JDQxk+fLjdOlarlZIlSzJ//nwKFy7Mtm3bePHFFwkICODpp59m5MiRHDt2jIiICNsXq6+vLxcvXrR7nQsXLtChQwf69evHTz/9xPHjxxk4cCAuLi52gePHH3/ktddeY+fOnWzfvp1+/frRuHFjWrdufc/9AXjzzTdZsGABP/74I0FBQUyaNIm2bdty6tQpfH19ee+99zh69CjLly+nSJEinDp1itjYWACmTZvGX3/9xR9//EGpUqU4f/4858+fz9R20/Pbb78RHBxM586d03xc0zS7+2vXrsXLy4vVq1fblplMJj788EOCg4O5evUqr732Gv369bN9DpK98cYbTJ06FX9/f95++206derEiRMncHJyAhJPw0yePJmff/4ZnU7Hc889x8iRI5k7dy6Q2Gq2bNkynnrqKTw9PdOs9161hIaG0r17d4YPH86AAQPYv38/I0eOtHuN06dP065dO8aPH8+sWbO4du0aQ4YMYciQIXbhLNupfCA8PFwBKjw8PMe2MWLefhU0aqkKGrVUfbfpdI5tRwhhLzY2Vh09elTFxsYmLoiPUmqMl2Nu8VGZrrtLly7qhRdesN3/5ptvVPHixZXFYkn3OVWqVFHTp0+33Q8KClKff/657T6gFi1aZHu9woUL3zkuSqmvvvpKAWr//v3pbmPw4MGqW7dutvt9+/ZVXbp0sVsnNDTU7nXefvttFRwcrKxWq22dL7/8Unl4eNj2p1mzZuqxxx6ze526deuqUaNGpVtLym1HRUUpJycnNXfuXNvjCQkJqnjx4mrSpElKKaU6deqk/ve//6X5WkOHDlWPP/64XY0PqmLFiqpz5852y4YPH67c3d2Vu7u7KlGihN2+FCtWTMXHx2f4mrt371aAioyMVEoptX79egWoefPm2da5ceOGcnV1Vb///rtSSqnZs2crQJ06dcq2zpdffqmKFStmu79x40ZVsmRJ5eTkpOrUqaNGjBihtmzZkqVaRo0apapWrWq3zjvvvKMAdevWLaWUUv3791cvvvii3TqbN29WOp3O7rOYUqqf4RQy+/0tLSNJpAOrEHmEk1tiC4Wjtp1JvXv3ZuDAgcycOROj0cjcuXN59tln0ekSz35HRUUxduxY/vnnHy5duoTZbCY2NpawsLBMvf6xY8dszfrJGjZsmGq9L7/8klmzZhEWFkZsbCwJCQk8+uijmd6P5G01bNjQriWgcePGREVF8d9//9lacqpXr273vICAgFSnAdJz+vRpTCYTjRs3ti1zcnKiXr16HDt2DIBBgwbRrVs39u3bR5s2bejatSuNGjUCEk+TtG7dmuDgYNq1a0fHjh1p06ZNmtvavHmzXUfgb775ht69e2eqznfeeYchQ4awcOFCPvroI7vHqlWrhrOzs92yvXv3MnbsWA4ePMitW7dsp+7CwsKoXLmybb2U752vry/BwcG2/QZwc3OjXLlytvt3H9umTZty5swZduzYwbZt21i7di1Tp07lgw8+4L333stULSEhIdStW9eu/nr16tndP3jwIP/++6+tRQYS+9ZYrVZCQ0Nz7ArPEkaSyIXyhMgjNC1Tp0ocrVOnTiil+Oeff6hbty6bN2/m888/tz0+cuRIVq9ezeTJkylfvjyurq507949Wzs+zps3j5EjRzJlyhQaNmyIp6cnn376KTt37sy2baSUfEohmaZpqfrNPIj27dtz7tw5li1bxurVq2nZsiWDBw9m8uTJ1KpVi9DQUJYvX86aNWt4+umnadWqFX/++Weq16lTp45df5hixYqlub0KFSoQEhJit8zPzw8/Pz+KFi2aan13d/vPZXR0NG3btqVt27bMnTsXPz8/wsLCaNu2bZbf57SOrbqrD5OTkxNNmjShSZMmjBo1ivHjxzNu3DhGjRqFyWTKllqioqJ46aWXGDZsWKrHMnN68X5JGEli14FVwogQ4h5cXFx46qmnmDt3LqdOnSI4OJhatWrZHt+6dSv9+vXjySefBBJ/yZ89ezbTr1+pUiV+/vln4uLibK0jO3bssFtn69atNGrUiFdeecW27PTp03brODs7Y7FYyEilSpVYsGABSilb68jWrVvx9PSkZMmSma45I+XKlcPZ2ZmtW7cSFBQEJPZx2L17NyNGjLCt5+fnR9++fenbty9NmjThjTfeYPLkyQB4eXnxzDPP8Mwzz9C9e3fatWvHzZs38fX1tduWq6sr5cuXv2dNPXv2pFevXixZsoQuXbpkeZ+OHz/OjRs3+PjjjwkMDARgz549aa67Y8cO25f5rVu3OHHixAO3MlSuXBmz2UxcXBwnT568Zy3BwcGp+rKk7EAMUKtWLY4ePZqp45edZDRNkoSUk55JGBFCZELv3r35559/mDVrVqrTABUqVGDhwoUcOHCAgwcP0qtXryy1IvTq1QtN0xg4cCBHjx5l2bJlti/llNvYs2cPK1eu5MSJE7z33nupvlxKly7Nv//+S0hICNevX8dkMqXa1iuvvML58+cZOnQox48fZ8mSJYwZM4bXXnvNdtrpQbm7uzNo0CDeeOMNVqxYwdGjRxk4cCAxMTH0798fgPfff58lS5Zw6tQpjhw5wtKlS21f2J999hm//fYbx48f58SJE8yfPx9/f/8Hmizs2WefpXv37jz77LOMGzeOnTt3cvbsWTZu3Mjvv/+OXq/P8PmlSpXC2dmZ6dOnc+bMGf766y8+/PDDNNcdN24ca9eu5fDhw/Tr148iRYpkaUK45s2b880337B3717Onj3LsmXLePvtt2nRogVeXl6ZquWll17i+PHjjBo1ihMnTvDHH38wZ84c4E5n3VGjRrFt2zaGDBnCgQMHOHnyJEuWLGHIkCGZrvV+SBhJkvI0jVXCiBAiEx5//HF8fX0JCQmhV69edo999tlnFCpUiEaNGtGpUyfatm1r13JyLx4eHvz9998cOnSImjVr8s477/DJJ5/YrfPSSy/x1FNP8cwzz1C/fn1u3Lhh10oCMHDgQIKDg6lTpw5+fn5s3bo11bZKlCjBsmXL2LVrFzVq1ODll1+mf//+vPvuu1k4Gvf28ccf061bN55//nlq1arFqVOnWLlyJYUKFQISW3FGjx5N9erVadq0KXq9nnnz5gHg6enJpEmTqFOnDnXr1rV9IT9IWNI0jd9//50vvviCZcuW0bJlS4KDg3nhhRcIDAxky5YtGT7fz8+POXPmMH/+fCpXrszHH3+cKjCm3Pfhw4dTu3ZtLl++zN9//52q/0lG2rZty48//kibNm2oVKkSQ4cOpW3btvzxxx+ZrqVMmTL8+eefLFy4kOrVq/PVV1/xzjvvANjmt6levTobN27kxIkTNGnShJo1a/L+++9TvHjOjnDT1N0npfKgiIgIvL29CQ8Px8vLK0e28cS0zRy5GAHAy83K8Vb7ijmyHSGEvbi4OEJDQylTpoxdZ00hHgYbNmygRYsW3Lp1K09O+T5hwgS+/vrrBxomndHPcGa/v6XPSBL70TQyz4gQQoiHz8yZM6lbty6FCxdm69atfPrppzl+CiYzJIwkSdmBVfqMCCGEeBidPHmS8ePHc/PmTUqVKsXrr7/O6NGjHV1W1vqMfPXVV1SvXh0vLy+8vLxo2LAhy5cvT3f9OXPm2KYgTr7l1WZYmWdECCFEdmvevDlKqTxziubzzz/n4sWLxMXF2To954VrFGWpgpIlS/Lxxx9ToUIFlFL8+OOPdOnShf3791OlSpU0n+Pl5WU3jvvu6XXzCrlQnhBCCOEYWQojnTp1srs/YcIEvvrqK3bs2JFuGNE0DX9///uvMJfIaBohhBDCMe57TJTFYmHevHlER0enOUVxsqioKIKCgggMDKRLly4cOXLknq8dHx9PRESE3S2nScuIEEII4RhZDiOHDh3Cw8MDo9HIyy+/zKJFi+zm308pODiYWbNmsWTJEn755ResViuNGjXiv//+y3AbEydOxNvb23ZLnk0upyilZAZWIYQQwkGyHEaCg4M5cOAAO3fuZNCgQfTt25ejR4+muW7Dhg3p06cPjz76KM2aNWPhwoX4+fnxzTffZLiN0aNHEx4ebrs96GWi7yVlEAFpGRFCCCFyU5a70Do7O9vmrK9duza7d+9m6tSp9wwYkHiRn5o1a3Lq1KkM1zMajbbZ4HJDylM0IPOMCCGEELnpgaeDt1qtxMfHZ2pdi8XCoUOHCAgIeNDNZqv4u8KI2SItI0KIvKt58+Z2F5cTaRs7diyPPvqoo8sQmZClMDJ69Gg2bdrE2bNnOXToEKNHj2bDhg22C0T16dPHbvKUcePGsWrVKs6cOcO+fft47rnnOHfuHAMGDMjevXhAqVtGJIwIITKWE4GgX79+Wbp4Wl6WkJDAp59+Sq1atXB3d8fb25saNWrw7rvvcvHiRUeXZ3Pt2jUGDRpEqVKlMBqN+Pv707Zt2zSv4SNyTpZO01y9epU+ffpw6dIlvL29qV69OitXrqR169YAhIWF2V206NatWwwcOJDLly9TqFAhateuzbZt29Lt8OooqcJI3r9cjxBC5Fnx8fG0adOGf//9lw8++IDGjRvj5+dHaGgov/32G9OnT2fixIlpPjchISFLF5B7UN26dSMhIYEff/yRsmXLcuXKFdauXcuNGzdyrQYBqHwgPDxcASo8PDxHXj/kcoQKGrXUdnvu+x05sh0hRGqxsbHq6NGjKjY2VimllNVqVdEJ0Q65Wa3WTNXct29fBdjdQkNDlVJKHTp0SLVr1065u7urokWLqueee05du3bN9tz58+erqlWrKhcXF+Xr66tatmypoqKi1JgxY1K95vr169PcfrNmzdTw4cNt92/evKmef/555ePjo1xdXVW7du3UiRMnbI+fPXtWdezYUfn4+Cg3NzdVuXJl9c8//9ie26tXL1WkSBHl4uKiypcvr2bNmpWFdzC1iRMnKp1Op/bt25fm4ymPc7NmzdTgwYPV8OHDVeHChVXz5s2VUkpNmTJFVa1aVbm5uamSJUuqQYMGqcjISNvzZs+erby9vdWiRYtU+fLlldFoVG3atFFhYWG2dcaMGaNq1KihfvrpJxUUFKS8vLzUM888oyIiIpRSSt26dUsBasOGDRnuz71qUUqpb7/9VpUsWVK5urqqrl27qilTpihvb2+7dRYvXqxq1qypjEajKlOmjBo7dqwymUz3PqB53N0/wyll9vvb8XPA5gF3t4xInxEhHCfWHEv9X+s7ZNs7e+3EzcntnutNnTqVEydOULVqVcaNGwckXsL99u3bPP744wwYMIDPP/+c2NhYRo0axdNPP826deu4dOkSPXv2ZNKkSTz55JNERkayefNmlFKMHDmSY8eOERERwezZswHw9fXNVN39+vXj5MmT/PXXX3h5eTFq1Cg6dOjA0aNHcXJyYvDgwSQkJLBp0ybc3d05evQoHh4eALz33nscPXqU5cuXU6RIEU6dOkVsbOx9HsFEv/32G61bt6ZmzZppPn73TNw//vgjgwYNsjs1otPpmDZtGmXKlOHMmTO88sorvPnmm8ycOdO2TkxMDBMmTOCnn37C2dmZV155hWeffdbudU6fPs3ixYtZunQpt27d4umnn+bjjz9mwoQJeHh44OHhweLFi2nQoEG6AyfuVcvWrVt5+eWX+eSTT+jcuTNr1qzhvffes3uNzZs306dPH6ZNm0aTJk04ffo0L774IgBjxozJwtF9OEkYAeLNFrv70mdECJERb29vnJ2dcXNzs5thesaMGdSsWZOPPvrItmzWrFkEBgZy4sQJoqKiMJvNPPXUUwQFBQFQrVo127qurq7Ex8dnadbq5BCydetWGjVqBMDcuXMJDAxk8eLF9OjRg7CwMLp162bbVtmyZW3PDwsLo2bNmtSpUweA0qVLZ/2A3OXEiRM0b97cbtmTTz7J6tWrAahevTrbtm2zPVahQgUmTZpkt37K/jilS5dm/PjxvPzyy3ZhxGQyMWPGDOrXTwyvP/74I5UqVWLXrl3Uq1cPSBxkMWfOHDw9PQF4/vnnWbt2LRMmTMBgMDBnzhwGDhzI119/Ta1atWjWrBnPPvss1atXz3Qt06dPp3379owcORKARx55hG3btrF06VLb8z744APeeust+vbtCyS+Bx9++CFvvvmmhBEkjABpjKaRob1COIyrwZWdvXY6bNsP4uDBg6xfv97W6pDS6dOnadOmDS1btqRatWq0bduWNm3a0L17dwoVKnTf2zx27BgGg8H2hQxQuHBhgoODOXbsGADDhg1j0KBBrFq1ilatWtGtWzfbl+2gQYPo1q0b+/bto02bNnTt2tUWau42d+5cXnrpJdv95cuX06RJk0zVOXPmTKKjo5k2bRqbNm2ye6x27dqp1l+zZg0TJ07k+PHjREREYDabiYuLIyYmBje3xNYrg8FA3bp1bc+pWLEiPj4+HDt2zBZGSpcubQsiAAEBAVy9etV2v1u3bjzxxBNs3ryZHTt2sHz5ciZNmsT3339Pv379MlVLSEgITz75pF399erVswsjBw8eZOvWrUyYMMG2zGKxpNqnguqBh/Y+DGQ0jRB5h6ZpuDm5OeT2oBfyjIqKolOnThw4cMDudvLkSZo2bYper2f16tUsX76cypUrM336dIKDgwkNDc2mo5e2AQMGcObMGZ5//nkOHTpEnTp1mD59OgDt27fn3LlzvPrqq1y8eJGWLVva/sK/W+fOne32K7k15W4VKlSwu0AqJIaA8uXLp3nqyd3d3e7+2bNn6dixI9WrV2fBggXs3buXL7/8Ekjs4JoVTk5Odvc1TcN61x+cLi4utG7dmvfee49t27bRr18/W2tFdtUSFRXFBx98YHf8Dh06xMmTJ/Ps1exzk4QRZDSNECLrnJ2dsVjsT/HWqlWLI0eOULp0acqXL293S/7C1TSNxo0b88EHH7B//36cnZ1ZtGhRuq95L5UqVcJsNrNz553WpBs3bhASEmI3cjEwMJCXX36ZhQsX8vrrr/Pdd9/ZHvPz86Nv37788ssvfPHFF3z77bdpbsvT09Nun1xd025J6tmzJ6tXr2b//v1Z2pdke/fuxWq1MmXKFBo0aMAjjzyS5nBgs9nMnj17bPdDQkK4ffs2lSpVuq/tJqtcuTLR0dGZriU4OJjdu3fbLbv7fq1atQgJCUn1uShfvrzdKNSCSk7TkMZ08NKBVQhxD6VLl2bnzp2cPXsWDw8PfH19GTx4MN999x09e/bkzTffxNfXl1OnTjFv3jy+//579uzZw9q1a2nTpg1FixZl586dXLt2zfblWbp0aVauXElISAiFCxfG29s71V/2d6tQoQJdunRh4MCBfPPNN3h6evLWW29RokQJunTpAiT2eWjfvj2PPPIIt27dYv369bZtvv/++9SuXZsqVaoQHx/P0qVLH/jL/NVXX+Wff/6hZcuWjBkzhiZNmlCoUCFOnDjB8uXL0ev1GT6/fPnymEwmpk+fTqdOndi6dStff/11qvWcnJwYOnQo06ZNw2AwMGTIEBo0aGA7RXMvN27coEePHrzwwgtUr14dT09P9uzZw6RJk2zHLjO1DB06lKZNm/LZZ5/RqVMn1q1bx/Lly+1a2t5//306duxIqVKl6N69OzqdjoMHD3L48GHGjx+fqXofajk00idb5fTQ3gV7z6ugUUtVhbeXqaBRS1WrKRkP8xJCZJ+MhgXmZSEhIapBgwbK1dXVbmjviRMn1JNPPmkbZluxYkU1YsQIZbVa1dGjR1Xbtm2Vn5+fMhqN6pFHHlHTp0+3vebVq1dV69atlYeHx30N7fX29laurq6qbdu2dkN7hwwZosqVK6eMRqPy8/NTzz//vLp+/bpSSqkPP/xQVapUSbm6uipfX1/VpUsXdebMmQc+PnFxcerjjz9WNWrUUK6urspoNKqKFSuqV1991W747d37kuyzzz5TAQEBtv356aefFKBu3bqllLoztHfBggWqbNmyymg0qlatWqlz587ZXiN5aG9Kn3/+uQoKCrLV+NZbb6latWopb29v5ebmpoKDg9W7776rYmJiMl2LUolDe0uUKGEb2jt+/Hjl7+9vt+0VK1aoRo0aKVdXV+Xl5aXq1aunvv322/s7wHlIdgzt1ZTK++ckIiIi8Pb2Jjw8HC8vr2x//d92hTF64SG8XZ0IjzVRtog760Y2z/btCCFSi4uLIzQ0lDJlysi5c5Fpc+bMYcSIEdy+fdvRpaRp4MCBHD9+nM2bNzu6lByX0c9wZr+/5TQNd/qMuDnrCY81yVV7hRBCZMnkyZNp3bo17u7uLF++nB9//NFuGLLImIQR7oQRV+fE85gymkYIIURW7Nq1i0mTJhEZGUnZsmWZNm1anrsOW14mYYQ7HVhdnSSMCCFEftCvXz/bPCB5wR9//OHoEvI1GU/EnUnP3J0Ts5mcphFCCCFyj4QR7kwHf+c0jczAKkRuywd96YUQaciOn10JI9h3YAVpGREiNyXPoxETE+PgSoQQ9yP5Z/dec+JkRPqMIB1YhXAkvV6Pj4+P7Xohbm4PPi27ECLnKaWIiYnh6tWr+Pj43HMyu4xIGEFaRoRwtOSr1Ka8gJkQIn/w8fHJ0pWm0yJhhDujadySOrBKy4gQuUvTNAICAihatCgmk8nR5QghMsnJyemBWkSSSRgB4k2ph/YqpaSpWIhcptfrs+UXmxAif5EOrKRsGbnzS1AaR4QQQojcIWGE1H1GAMwyvFcIIYTIFRJGSDma5s5ZK+k3IoQQQuQOCSNAfBqnaWREjRBCCJE7JIyQep4RAItFwogQQgiRGySMkGI6eKcUYUSmphZCCCFyhYQR7rSMOBt0GHSJw3mlz4gQQgiROySMkCKM6HXok8KI9BkRQgghcoeEEe7MM2JM2TIifUaEEEKIXCFhhDstI0aDPkXLiMwzIoQQQuQGCSNAfIo+I3rpMyKEEELkqgIfRixWZQseiWEk8ZBInxEhhBAidxT4MJJ8igZkNI0QQgjhCBJGUoYRvZymEUIIIXJbgQ8j8RaL7d9Oeg2DXob2CiGEELlJwojpzrBeTdOkZUQIIYTIZQU+jCTPMeJsSDwUBhnaK4QQQuQqCSPmOy0jADpNWkaEEEKI3CRhJMVU8ICtz4iEESGEECJ3SBi56zRN8jwjEkaEEEKI3CFhJMVU8JCyz4iEESGEECI3FPgwEm9OHNp7p2VETtMIIYQQuanAh5EEc3qjaSSMCCGEELmhwIeR+Ls6sN5pGZGhvUIIIURuKPBh5O6WkeQwYrZIy4gQQgiRGySMpDPpmVVJGBFCCCFyQ4EPIymng4cULSPSZ0QIIYTIFQU+jKRuGZF5RoQQQojcJGHEnE7LiPQZEUIIIXKFhJF0R9NIGBFCCCFyg4SRVNPBS58RIYQQIjcV+DASb0qcgfXu6eBlNI0QQgiROwp8GEm3ZUT6jAghhBC5osCHkfh0poOXGViFEEKI3FHgw0jqDqyJ/5c+I0IIIUTukDByd8uIXkbTCCGEELlJwshdfUZ0moymEUIIIXJTgQ8jd08Hb5B5RoQQQohcVeDDSHLLyN0zsEoYEUIIIXKHhJF0RtPIaRohhBAid2QpjHz11VdUr14dLy8vvLy8aNiwIcuXL8/wOfPnz6dixYq4uLhQrVo1li1b9kAFZ7c7o2kSJz3T62VorxBCCJGbshRGSpYsyccff8zevXvZs2cPjz/+OF26dOHIkSNprr9t2zZ69uxJ//792b9/P127dqVr164cPnw4W4rPDqmv2istI0IIIURuylIY6dSpEx06dKBChQo88sgjTJgwAQ8PD3bs2JHm+lOnTqVdu3a88cYbVKpUiQ8//JBatWoxY8aMbCk+O9yZDt5+NI30GRFCCCFyx333GbFYLMybN4/o6GgaNmyY5jrbt2+nVatWdsvatm3L9u3bM3zt+Ph4IiIi7G45RVpGhBBCCMfKchg5dOgQHh4eGI1GXn75ZRYtWkTlypXTXPfy5csUK1bMblmxYsW4fPlyhtuYOHEi3t7etltgYGBWy8y0u6eD1yfNxGqVMCKEEELkiiyHkeDgYA4cOMDOnTsZNGgQffv25ejRo9la1OjRowkPD7fdzp8/n62vn9Ld08FLy4gQQgiRuwxZfYKzszPly5cHoHbt2uzevZupU6fyzTffpFrX39+fK1eu2C27cuUK/v7+GW7DaDRiNBqzWlqWKaVknhEhhBDCwR54nhGr1Up8fHyajzVs2JC1a9faLVu9enW6fUxym8miUEmZQ/qMCCGEEI6RpZaR0aNH0759e0qVKkVkZCS//vorGzZsYOXKlQD06dOHEiVKMHHiRACGDx9Os2bNmDJlCk888QTz5s1jz549fPvtt9m/J/chuVUEwGhImmdEJ/OMCCGEELkpS2Hk6tWr9OnTh0uXLuHt7U316tVZuXIlrVu3BiAsLAyd7k5jS6NGjfj111959913efvtt6lQoQKLFy+matWq2bsX9ym5vwik6MCa3DJikZYRIYQQIjdkKYz88MMPGT6+YcOGVMt69OhBjx49slRUbkkOI3qdZgshyadprErCiBBCCJEbCvS1ae4eSQOgT2rZkT4jQgghRO4o0GEk3pw4+2ryKRq40zIio2mEEEKI3FHAw4j9sF6QPiNCCCFEbivQYeTuqeBBWkaEEEKI3Faww4g5dRjR2eYZkaG9QgghRG6QMIJ9B1ZpGRFCCCFyl4QR0u4zYpGhvUIIIUSuKNBh5O4r9gIYkob2WqQDqxBCCJErCnQYSbAkDu1NngoeUoymkdM0QgghRK4o2GEkrZYRvfQZEUIIIXKThBHsO7DqNGkZEUIIIXJTgQ4jafcZkZYRIYQQIjdJGME+jOgljAghhBC5qkCHkbSG9kqfESGEECJ3FewwksZ08HqZgVUIIYTIVQU7jGQwz4hVgVVaR4QQQogcJ2EEMOpTt4yAzMIqhBBC5IYCHUbizYmTnqV1mgak34gQQgiRGwyOLsCR7j5N80fIHxy9fhyDpxPm6PIy14gQQgiRCwp2GLEkj6bRc+b2GT7c8SEAriVBKY3+qxbyYvUBtAxq6cgyhRBCiIdagT5Nk7Jl5Od/vwWgbIKJcgkJaJri6M3DjNz4OqdunXJkmUIIIcRDrUCHkeRJz0wqgr/PrgDg/YgEfv/vBqvDLvBYTCxmZWHM5tFYrBZHliqEEEI8tAp0GEluGTlwcynxykKV+Hhqtf6EOuYfeC12FG9TDHerlX9vHef3kN8dXK0QQgjxcCrQYSTebAXNxM5rCwHoE29Aq9IVk86ZbdaqGFrNYMStSACm7pnC5ejLjixXCCGEeCgV6DDyVK0StKx9gQgVSzGzmdbV+4HeyTbxWXyhR3j60Zd5NC6eGGsC47e+j5K5R4QQQohsVaDDyPMNgrjJ3wD0jozFqU5/IMXF8pRC1/R1xlq8MCjFxkvbWRa6zGH1CiGEEA+jAh1Gtl/czqnoC7harXQLagvuhQEwpLxyr8FIuY4zGHg7AoAxW99j9+XdDqtZCCGEeNgU6DDyU9Jw3qcio/FqONS23HaxPEvSKZlSDRhYvhvNo2OIt5oYunYwR28czfV6hRBCiIdRgQ0jJqsJr8irOClFb69g8K9qe8yuZSSJU5vxfKovQZ3YOKLNsby86kXOhJ/J9bqFEEKIh02BDSNOSmPSuZOsC7tAYP2hdo/pkltGrNY7C53dcen9J9PjXKgcH8+thHBeXDWQn4/+zL4r+4gxxeRm+UIIIcRDo+BOB683wMB1+BycB8Ht7R5Kq2UEAI+ieDy3kK9mtaFfIR2hXGXS7kkAaGiU8S5D5cKVqeRbicqFK1O1SFVcDC65sjtCCCFEflVwwwiATyA0eyPVYn16YQSgSAV8n/2NOT93Yb67M4eNRo66unFVU5wJP8OZ8DMsPbMUgGJuxfih7Q8EeQXl6G4IIYQQ+VnBDiPpSJ5nJM0wAlCqAb49fuallW/DlZMAXNfrOOrszFGjM8dc3Djg4sKVmCv0X9mfOe3mUNKzZG6VL4QQQuQrEkbSYBtNk14YAXikTeIt4hKc20qRs1toemEvTa8dh9sR3NDpeCGgGGe4woBV/ZnT7kf83f1zaQ+EEEKI/EPCSBoM+gxO09zNKwCqdU+8AVhMcOMUhU+s5Pv1H9AvoBhhURdtLSR+bn45WLkQQgiR/xTY0TQZyVTLSLpPdoKileCxEfi1/4wfLl2lhMlMWGQYQ9cNlav/CiGEEHeRMJIGvZbcMmK9x5r3UOd/+LeZyPeXr+BpsXLkxhG5+q8QQghxFwkjaXiglpG71X+Jki3GMvzWbQCm7/uC67HXH/x1hRBCiIeEhJE0ZKnPSGY0Hkb34s2oEh9PlDmWT3d9mj2vK4QQQjwEJIykQX+vob3385odJvHe7Vg0pVh2dhk7L+3MttcWQggh8jMJI2kwZOdpmmTeJany2CieiYwCYPz2D0iwJGTf6wshhBD5lISRNGQ4A+uDqP8yQw0lKGy2cDbyPDP2z8je1xdCCCHyIQkjaUgeTZOtLSMAegNeHb/grZu3AJh9ZDY/Hfnpnk+LSoji1K1THLl+hH1X9rH78m7izHHZW5sQQgjhIDLpWRr0yR1YLQ84tDctgXVpV+lZzp/8k2m+Pny651O8jF50Ld811aqx5ljmHJ7N7EPfE2s12T1WyujLdx1/o7hH8eyvUQghhMhF0jKSBttVe7O5YcSm9YcM8K5Cn/AIAMZsfZ+1YWttD1uVlb9P/03HP9sy8+BXxFpNeFks+JvNBJkS/x0Wf5PnF3flzK3TOVSkEEIIkTukZSQNd/qM5EDLCIDRA633n4yc252IyBAWe3rw6vpXMeqNmK0mzOrOLK3FTWZejYyn7SNPobn7gYs3V64d5aXLKzntDH3/7sHX7edQxa96ztQqhBBC5DBpGUlDjoymuVtSIBnjFkz7qGgUijhLnC2IeFitjLh5i798GtFuwHa0JyZD81HQ4GWKdZrGnKpDqBofz21l4oVlz3Pw0q6cq1UIIYTIQRJG0mCbZyTHztMkMXpg6P0nk9wqsSrsAsvPX2BN2AU2XLzBJnNR+nf9FWP3H8CzWKqn+jQcyvcNx1M/Lp4YrIxeM5hYc2zO1iuEEELkADlNk4ZcaRlJZvSAvn8TcPUoOLuBe9HEZZngXu1pvnD24Mktr3PeEMeMdW/yRpvpOVywEEIIkb2kZSQNOTbPSHp0OvCvCr5lMx1EknkEd+C9Ig0B+OXiev69sC0nKhRCCCFyjISRNGTrhfJyQdP2M+iYoGHVNN5f96rM7CqEECJfkTCShuTTNFaVP8IIzm6Maj4JX4uF09YYvtv4tqMrEkIIITJNwkgabC0jOd2BNRv5VGjH24VqA/B92AqOXJTRNUIIIfIHCSNpMOT0PCM5pE37mbROALOm8drql7kVe9PRJQkhhBD3JGEkDclDe/NLn5FkmosnY1vOoJTJzEVMvPHXs5itZkeXJYQQQmRIwkga9ElHJddG02Qjr7LN+KJSf1ytVnbGXWLa2tccXZIQQgiRIQkjacivLSPJKjQeyYdeidPDz764nhWHfnRwRUIIIUT6ZNKzNNhG0+TTMALQtsuPHPm5KbN10by1dzKrQpfRo9ZQ6pdohE7TYbKaOHnrJEdvHOVa7DVux97gVsw1zFYT3Ss9R6MSjRy9C0IIIQqILIWRiRMnsnDhQo4fP46rqyuNGjXik08+ITg4ON3nzJkzh//97392y4xGI3FxcfdXcS7Ib/OMpMngzPBuC7g0rw0rjDpW3zrK6rWDCDJ44Wv05ljMReJSXJAvpdUXNtO2+GO82fgDiroVzeXChRBCFDRZOk2zceNGBg8ezI4dO1i9ejUmk4k2bdoQHR2d4fO8vLy4dOmS7Xbu3LkHKjqnGfS5PANrDtF7leDTXhtY4N+eZ2LMuFutnDNHsD/6PHHKgqfFSoPYWLpFRDHgdjhv3LjFsxGR6JRi5cUtdP6zHXMP/4jKL/OtCCGEyJey1DKyYsUKu/tz5syhaNGi7N27l6ZNm6b7PE3T8Pf3v78KHeBOy0j+GtqbJg8/Hmk7iXfNH/Lav7+z9uAsrFYT1QpXpnTxeuj8q4GnP7h4g9ELbpziqX+GMj7uLP+6wMd7JxMbc40B9UY6ek+EEEI8pB6oz0h4eDgAvr6+Ga4XFRVFUFAQVquVWrVq8dFHH1GlSpV014+Pjyc+Pt52PyIi4kHKzDK99nC0jNgxGHGr1YdOtfpkvJ5fMJX6ruTnQ38ya/P7TPUwMP3oj1QuVotGQY/nTq1CCCEKlPseTWO1WhkxYgSNGzematWq6a4XHBzMrFmzWLJkCb/88gtWq5VGjRrx33//pfuciRMn4u3tbbsFBgbeb5n35aHoM/IgNA1d9R4MeG41T8WasWowasNrXIhM/z0TQggh7td9h5HBgwdz+PBh5s2bl+F6DRs2pE+fPjz66KM0a9aMhQsX4ufnxzfffJPuc0aPHk14eLjtdv78+fst8748LH1GHph3Sd5u8w1V4hO4jYVXl/Ymzpx3Ox4LIYTIn+4rjAwZMoSlS5eyfv16SpYsmaXnOjk5UbNmTU6dOpXuOkajES8vL7tbbkqeZ6TAhxHAWLYpn1d9hUIWC8cSbjJ+1SBHlySEEOIhk6UwopRiyJAhLFq0iHXr1lGmTJksb9BisXDo0CECAgKy/NzcYijop2nuEtBoOJMK1UWnFEuu7WHpv7McXZIQQoiHSJbCyODBg/nll1/49ddf8fT05PLly1y+fJnY2FjbOn369GH06NG2++PGjWPVqlWcOXOGffv28dxzz3Hu3DkGDBiQfXuRzfQ6OU1ztwadvuNlqycAE/Z9wcXwvD08WwghRP6RpTDy1VdfER4eTvPmzQkICLDdfv/9d9s6YWFhXLp0yXb/1q1bDBw4kEqVKtGhQwciIiLYtm0blStXzr69yGbSMpIGgzMDu/5KjQQzUZpi9LJ+WKxpT5omhBBCZIWm8sGMVhEREXh7exMeHp4r/UfWh1zlf7N3U7WEF0uHNsnx7eUn5/fNovvBKcTodAwP6siA5hMdXZIQQog8KrPf33KhvDTYWkYseT6n5brAWi8w2jNxjpgvz/7Nkf+2OrgiIYQQ+Z2EkTQk9xmx5v1GI4fo0mk2rc16zJrGq2sGc+76MUeXJIQQIh+TMJIGQ9LQXukzkjbN6M77bb6mtMnMJc1Cn6XPcOy/HY4uSwghRD4lYSQNMprm3nwCGzCnxQwqmSzc1BQvrBnInlP/OLosIYQQ+ZCEkTRIn5HMKVyuJT90mEttkyJKg5e3jGLKsgGsP/Y7N2Nv2NZTShGVEEW0KeOrOwshhCiYHuhCeQ8raRnJPM/iNfm629+8sfBJNhgszLm2kznXdsKu8fjjRAJWwrFgATTgEWdf6vrXo07ZdtQPqI+Hs4ejd0EIIYSDSctIGgr8hfKyyKVQGT5/dg2f+Nanm9WVcgkmAC5j4mZSEAFQQEjCTX4JW8GIDSN44vfmHLl2yGF1CyGEyBukZSQNBhlNk2UG9yJ06PQ9HQASYgg/u5HQCztxd3LHy+iDt6svUeHn2XNmOXsiTrPZ6MRFJ+i/7Dmmt/6GusUbOHoXhBBCOIiEkTTYWkYsVgdXkk85u+H9SHsefaS93WIXoF3jEbQzxRF18FeG7v2YPS5GXl79IpObfkqLMm0dU68QQgiHktM0aTDIVXtzlpMLHnVe4Ktmn9M8Np4EFK9uGsmyE4scXZkQQggHkDCSBr1e+ozkBpeKT/B5m2/pHB2HBXh/+xhCb59xdFlCCCFymYSRNOg1GU2TWwxlm/Nhx59pGJdAPIp3Vr6I2Wp2dFlCCCFykYSRNKQcTZMPriOY7+lKNWBc5QF4WqwcirvCD7smO7okIYQQuUjCSBqSR9MASONI7vBv/DqjNT8Avj4+l2PXjzi4IiGEELlFwkgakvuMgJyqyTU6HR27zKZ1bAJmDd5e/QrxlnhHVyWEECIXSBhJQ8qWEQkjuUfzLcO7jw7F12LhVMJNZmwd5+iShBBC5AIJI2nQpwgjZqvMNZKbfOsP5gNDSQB+PPMXuy5sc3BFQgghcpqEkTQkzzMC0jKS6zSN5l1m0z06HqXB2+tfJTw+3NFVCSGEyEESRtKQomFE5hpxBO8SvNFoLEEmE1csMYxf/5qMahJCiIeYhJE0aJomV+51MLdHezHRoxp6pVhxZRf/nJTZWYUQ4mElYSQdEkYcr1rnb3g5JrHPzoQdH3L69mkHVySEECInSBhJh0HCiOO5+TKg9Rc8GhdPlDLz/N/PsOXCFkdXJYQQIptJGElHyllYheMYKrRhamBHasXFEWmNZ/CaQfxy5GfpQyKEEA8RCSPpuNMyIkN7Hc233WS+K/8cXSOjsAKf7JnEqA2v88+Zfzh9+7Rcy0YIIfI5g6MLyKukZSQP0elwbjmGcb4VqLBhNFMKebI8bDXLw1YDYNQ54+dWFBeDC0a9EVeDK/UC6tEzuCc+Lj6OrV0IIcQ9SRhJhy2MWCSM5BVazV70KRRElYV9WO5kIcTZmRPOTsSQwH9R/9mtu+fKHmb/+wNPBXenT+U+FPco7qCqhRBC3IuEkXQkT3wmHVjzmNKNqT1wG7VProKL+7Fe3Md/N45zEwtxmka8pnFdr+d3L0+OGWHusbnMO/Ybo+uP5pmKzzq6eiGEEGmQMJIO29Be6SiZ93gWg1rPQ63n0QGlzAmUio8AUwyYYiHqCk/t/ZEdZ5bxg5cHO11dmLBzAl5OnrQv94SjqxdCCHEXCSPpkKG9+YjBGQxF7tz3C0Yr05SG4RdosPNrPgr5hXleHry9ZTTeLoVoVKKR42oVQgiRioymSYf0GXkIeJdAa/MhbzWdSNuoGMwoRqx9hcPXDjm6MiGEEClIGEmHzMD68NDXeJaP6r5F/dg4YpWFV1b8j/8i/7v3E4UQQuQKCSPpuDO0V+YZeRg41xvI1KovUyk+gVvWeN5Z+SIWq8XRZQkhhEDCSLqkz8jDx/2x1/msVGfcrFb2RZ/npz1fOLokIYQQSBhJl5ymeTiVbD2RUaoQANOPziHk+lEHVySEEELCSDpknpGHlN7Ak0/OpXmcCZMGb696iQRLgqOrEkKIAk3CSDpkOviHl1YoiDF136KQxcIJ021mbnrH0SUJIUSBJmEkHQa9nKZ5mBWp1Y8xnlUBmHVuOTvOrHJwRUIIUXBJGEmHTpOWkYddy84/8FSChtI0Rm1+gyuRFx1dkhBCFEgSRtJxZzSNDO19aBk9Gf3ETwQnmLmJlTf+7onJanJ0VUIIUeBIGEmH9BkpGFyKP8pntUbiYbWy33STL1a+4uiShBCiwJEwko7kPiNWCSMPvVK1+zO+SGMAfrq6g9UHvndwRUIIUbBIGEmHPmlor7SMFAwtn/iK/2mJ84+MOvAFi3d95uCKhBCi4JAwkg6ZgbWA0ekZ1m0Brc0GTJrGe8dmM3lpP5kyXgghcoGEkXTIaJqCx+Dux+TeG3nZ4A/Ajzf2MmReSyJirju4MiGEeLhJGEmHtIwUTDoXLwb3WsWnRZvhYrWyxXSDdr+34MtlLxIefc3R5QkhxENJwkg69EkdWM0WCSMFjqbRrv0M5jz6OmXNViJ18PW17bSZ34LP/u4roUQIIbKZhJF02FpGlISRgqpKzRdY2Hs7UwJaU9FkJUbTmH1zH13mt2TV/u9Q8tkQQohsIWEkHXqZ9EwAehcv2rT5jD/67OHLkp0oY7ZyQ1O8/u80Rsxvz9WIC44uUQgh8j0JI+kwyKRnIgXN2ZWmLT/iz+6reMngj0Ep1sVeoOvCdhw7v8XR5QkhRL4mYSQdyfOMWKTPiEjB2bsEQ3qv5vcqQ6hkshCpwatrh3BbRtwIIcR9kzCSDn3SkZGWEZGWR+q+zHdPzKWk2cIFzcJbfz0jc5IIIcR9kjCSDlvLiIQRkQ7vgJp8UX0oLlYrW+OvMnPtq44uSQgh8iUJI+mQ0TQiM4LrDmKMT20Avr24nnVHfnVwRUIIkf9IGEmHbTSN9BkR99Cx8w/0troD8O7uidyIvuLgioQQIn+RMJIOGU0jMk3vxOtPzrd1aP123UhHVySEEPmKhJF0yDwjIiucfAJ5vWw3AP64sZ/zN086uCIhhMg/JIykQy8tIyKL6jd9l0YmMGsaM9ZL64gQQmSWhJF0yIXyRJYZjIyo0h+AZVFnOHZxp4MLEkKI/CFLYWTixInUrVsXT09PihYtSteuXQkJCbnn8+bPn0/FihVxcXGhWrVqLFu27L4Lzi3JQ3ulZURkRaX6Q2lv0gMwddM7Dq5GCCHyhyyFkY0bNzJ48GB27NjB6tWrMZlMtGnThujo6HSfs23bNnr27En//v3Zv38/Xbt2pWvXrhw+fPiBi89JyS0jVgkjIit0eobWeR2DUmyNv8KO03k/eAshhKNp6gEuPXrt2jWKFi3Kxo0badq0aZrrPPPMM0RHR7N06VLbsgYNGvDoo4/y9ddfZ2o7EREReHt7Ex4ejpeX1/2WmyUL9v7H6/MP0uwRP358oV6ubFM8JJTio9kN+E0fQ1WDF7/22oKmaY6uSgghcl1mv78fqM9IeHg4AL6+vumus337dlq1amW3rG3btmzfvj3d58THxxMREWF3y20GvfQZEfdJ03jpsTG4Wq0cNkew5eQSR1ckhBB52n2HEavVyogRI2jcuDFVq1ZNd73Lly9TrFgxu2XFihXj8uXL6T5n4sSJeHt7226BgYH3W+Z902nJo2lkaK/IusKPdOBpzQeAr3dP5gEaIIUQ4qF332Fk8ODBHD58mHnz5mVnPQCMHj2a8PBw2+38+fPZvo17kdE04kH1azAKo9XKv+Zwtp9e7uhyhBAiz7qvMDJkyBCWLl3K+vXrKVmyZIbr+vv7c+WK/fTYV65cwd/fP93nGI1GvLy87G65TeYZEQ+qSHAneigPAL7e9Ym0jgghRDqyFEaUUgwZMoRFixaxbt06ypQpc8/nNGzYkLVr19otW716NQ0bNsxapbksuc+IjKYR903T+F+9kThbFftNN9l9du29nyOEEAVQlsLI4MGD+eWXX/j111/x9PTk8uXLXL58mdjYWNs6ffr0YfTo0bb7w4cPZ8WKFUyZMoXjx48zduxY9uzZw5AhQ7JvL3KAzDMiskPRKt15ymoE4OudEx1cjRBC5E1ZCiNfffUV4eHhNG/enICAANvt999/t60TFhbGpUuXbPcbNWrEr7/+yrfffkuNGjX4888/Wbx4cYadXvMC6TMisoWm0b/WcAxKsTv+KnvCNji6IiGEyHMMWVk5M+e8N2zYkGpZjx496NGjR1Y25XDSZ0RkF/8az/Hk3s+Z72Tm860f8FPJJuh1ekeXJYQQeYZcmyYdemkZEdlFp+OlWsNwt1r5N+E6fx741tEVCSFEniJhJB13WkZknhHx4IrV7MdQCgPwxaGvuRpz1cEVCSFE3iFhJB3JfUbMFmkZEdlA03i2w1dUjU8gCiufrB3h6IqEECLPkDCSDm9XJwBuRifI/BAiW+iLVWFMyfbolWLVzUNsCl3l6JKEECJPkDCSjmJeLgDEm62Ex5ocXI14WFRsNYHn4hJb3SZsfY8YU4yDKxJCCMeTMJIOFyc9hdwSW0cuR8Q5uBrx0HB255Um4wgwm7loiWHU6lcwWSXsCiEKNgkjGUhuHbkULmFEZB+3Kk/ykcsjGK1WNlzby+i1wzBbzY4uSwghHEbCSAb8vRPDyBUJIyKb1XlyNl8kuGFQipUXt/D+xjewKhm5JYQomCSMZCAgKYzIaRqR7dx8eazX30yO0aFXir/D1jBu8zsSSIQQBZKEkQwkn6a5ImFE5ARPf1r2/IuJkRZ0SrEgdCnD17xCtCna0ZUJIUSukjCSAX/pMyJyWqHStH9mIR+Hx+FsVWy4uJXn/n6a85HnHV2ZEELkGgkjGSiWfJpGwojISUUr0f7ZJcyJBD+zmVORYfT8qwc7L+10dGVCCJErJIxkILnPiJymETmuWBWqvbCO36zFqBofT7g5mkGrX2Lvlb2OrkwIIXKchJEMJJ+muRVjIs5kcXA14qHnUZRi/ZYzu1AjmkfHYFIWhq0exJnwM46uTAghcpSEkQx4uzphNCQeImkdEbnCyRWX7rOZFNSF6nHxRFhieWXFC1yPve7oyoQQIsdIGMmApmm2uUak34jINZqGa/tPme5Vk0CTiQtxNxiycoBMHS+EeGhJGLmH5FM1MteIyFU6Pb7dZvMV/vhYLBwJP817G990dFVCCJEjJIzcg790YhWO4uxGUM8/mR7jhEEpVl3YyKbzmxxdlRBCZDsJI/cgc40Ih3IvwqM9F9I7KvHz9/GWd4i3xDu4KCGEyF4SRu5BZmEVDle4HINqvERRs5nzCbeZtf9LR1ckhBDZSsLIPQRIB1aRB7g3GsEbZjcAfjjyo8zQKoR4qEgYuYditj4j0jQuHEjvRNs2U6kfG0c8ViZtetvRFQkhRLaRMHIP/ilO01itysHViIJMK/MYbxdpiEEpNlw/wIZz6xxdkhBCZAsJI/fg52lEp4HZqrgeLa0jwrHKtpvM81EJAHyx7QMsVpkZWAiR/0kYuQcnvY4iHkYAroRLGBEO5lGUAbWG4mWxcDrhJstPLnZ0RUII8cAkjGSCbRZWGVEj8gCv+i/zvwQDADP3TMFkNTm4IiGEeDASRjIheXjv5fBYB1ciBKB3olf9N/G1WDhvjuSvo785uiIhhHggEkYyIUBaRkQe41ajFwOShvp+fWAGCZYEB1ckhBD3T8JIJtxpGZE+IyKP0Ol4+rH3KGo2c9kSy5+HZjm6IiGEuG8SRjLBX2ZhFXmQsVJnXtIKAfDdv98Ra5bTiEKI/EnCSCYkd2C9JH1GRF6iaTzZbDwlTGauqwTm7P7c0RUJIcR9kTCSCf4yC6vIo5zKPc4IpxIAfHdiHmfDQx1ckRBCZJ2EkUxIPk0TFW8mKt4MwKL9//H45A0c+i/ckaUJQdv2M2gcG4cJxfi1w1FKZgoWQuQvEkYywd1owNOYOK/D5fA4jl+OYNSCQ5y5Hs2vu8IcXJ0o6LSiFXmn3NMYrVZ2RoayNOQPR5ckhBBZImEkk5IvmHfuRjTDfztAgtkKwPbT1x1ZlhAABLZ4n5cTnACYvOsTwuOlxU4IkX9IGMmk5LlGxv59hJArkRR2d0anwdkbMdKxVTiewUjf1lMpl5DATWXi841vOboiIYTINAkjmZQ818j5m4nBY/LTNahWwhuA7advOKwuIZI5lW3G+4XrA7Dg0hYWHZvn4IqEECJzJIxkUnInVoB+jUrTIrgoDcoVBiSMiLyjVvup9ItO7GQ9ZucElp5Y4OCKhBDi3iSMZFK5ou4ABBfz5K32FQFoVK4IANskjIi8wrUQr3X6iaej4lEavLN9LCtP/e3oqoQQIkMGRxeQX3SsXhydpvFY+SK4OOkBqBNUCINO48LtWM7fjCHQ183BVQoBWmBd3un4I6Z/+rLI3ciorW+j1+lpVbaDo0sTQog0SctIJjnpdXR5tASFPYy2Ze5GAzUCfQA5VSPyFl1QQ8Z0mEXH6DgswGubR/HZ9vGYLCZHlyaEEKlIGHlAjZL6jWyTIb4ij9GXfowP233HM1GxKGD2id/pvagzZ8LPOLo0IYSwI2HkATUsm9SJ9cwNmflS5DmGss15t/sSvog14mOxcCz6P55Z/BR/nVjo6NKEEMJGwsgDqhVUCGe9jisR8YRej3Z0OUKkVqwKLftvZkGR5jSIjSUOC+9sH8O3e6dKgBZC5AkSRh6Qi5OeWkE+QGLriBB5kpMrRTvP5Jtmn9M/Mg6A6Ye/Z8Lmd7BYLQ4uTghR0EkYyQYNy8oQX5E/6Cp1YkSPxbwVaUZTit9D/2bkqpeIt8gVqYUQjiNhJBs0TOrEulP6jYj8oFgVevdewaexTjgpxZorO3l/zTD57AohHEbCSDaoEeiNi5OO61EJnLwaleY68WYLFqv8shd5RKEg2vZZzUyTN3qlWHZ5G4uOznV0VUKIAkrCSDYwGvTUDCwEwP6wW6ke/+9WDLU/XMNrfxzI5cqEyIB7ERo89w9DYjUAJu6ZxMmbJxxclBCiIJIwkk0eLeUDwIHzt1M9tv74VaLizfzz7yWi4825W5gQGXH14YWOs2gcG0ccipErBxBjinF0VUKIAkbCSDapUdIHgAPnw1M9ti/sNgBmq2JX6M1crEqIe9MF1uWjKi9R1GzmTMItPtrwhqNLEkIUMBJGssmjSdPCn7gSSUyCfevHvhSnbrackplaRd7j+9jrfGwsj04pllzcxIqTixxdkhCiAJEwkk38vV0o5mXEYlUcuRhhW349Kp5zN+40e2+VMCLyIk2j7lM/8mJs4t2J2z/kdtxth5YkhCg4JIxko+RTNQdT9BvZn3SKJsDbBYDjlyO5mjTplBB5ipsvL7aeSvmEBG4qE5M2jHR0RUKIAkLCSDZKvoJvyk6syadomlbwo0pxL0Cu8CvyLqfyLRlXuAE6pfj7yk42n1vr6JKEEAWAhJFsVDOtMHIuMYzUCvLhsfKJM7VuOSmnakTeVa39VJ6LswIwbvNook1yzSUhRM6SMJKNqpb0RtPgv1uxXI+Kx2yx8u9/iaNrapUqROOkMLL11HWZ7VLkXa4+DG7yESVNJi5bYvli0zuOrkgI8ZCTMJKNvFycKOfnAcC//93m+OVIYk0WvFwMlPPzoG5pX5z1Oi6Gx8kVfkWe5lalK2M9qwIw77+1rD2z3MEVCSEeZlkOI5s2baJTp04UL14cTdNYvHhxhutv2LABTdNS3S5fvny/NedpKecbSe4v8mipQuh0Gq7OemoHJc7UKqNqRF5Xv+PXPBdtAmD05rcIuRni4IqEEA+rLIeR6OhoatSowZdffpml54WEhHDp0iXbrWjRolnddL7waKA3kDiixtZfJGl2VoDHKiT1G5EwIvI69yK83vZLGsTGEYuVYcv7cTNOJu0TQmS/LIeR9u3bM378eJ588sksPa9o0aL4+/vbbjrdw3mGKHlEzcH/brM3LDmMFLI9ntxvZPvpG3LhPJHnGcq1ZHL1oZQymbhojuLVZf0wWUyOLksI8ZDJtUTw6KOPEhAQQOvWrdm6dWuG68bHxxMREWF3yy8q+nvhrNdxO8bE+ZuxaNqd69YAVCvhjaeLgYg4M4cvpJ46Xoi8xrvhUKYXeQwPq5V9kaG8t2448ZZ4R5clhHiI5HgYCQgI4Ouvv2bBggUsWLCAwMBAmjdvzr59+9J9zsSJE/H29rbdAgMDc7rMbONs0FE5aT4RgEeKeuLl4mS7r9dpNCpXGJBTNSKf0DTKdpzJJIqiU4p/Lm6m58LOnL592tGVCSEeEjkeRoKDg3nppZeoXbs2jRo1YtasWTRq1IjPP/883eeMHj2a8PBw2+38+fM5XWa2Sr5ODSTOL3K3Zo8k9pdZvP+CDPEV+YPBmSZP/8mXcS74WiycjLnIM0ue4o9jv8lnWAjxwBzScaNevXqcOnUq3ceNRiNeXl52t/wkZRipmaK/SLKONQJwddJz8mpUmlfxDY818d8tuYy7yGPcC/PYCxtZ4NuUxjGxxGPlw10f8dySp/jr9F9y6kYIcd8cEkYOHDhAQECAIzadK2qkbBlJI4x4uTjRtWZxAH7ZGWb3WLzZQvevtvH4lI2cuhqZo3UKkWXO7hTp+jUzm3zCyPBYnJTi3/BTvLPlHVr91pQpuyZxKeqSo6sUQuQzWQ4jUVFRHDhwgAMHDgAQGhrKgQMHCAtL/FIdPXo0ffr0sa3/xRdfsGTJEk6dOsXhw4cZMWIE69atY/DgwdmzB3lQ6cJuPFmzBF0fLU45P/c01+ldPwiAFYcvcS3yzl+UP207x8mrUSSYrfyyIyzN5wrhaLqq3ejbZx2rXKoy9FY4/mYzty0xzDn2Mx0WtOXtDa9z4tYJR5cphMgnshxG9uzZQ82aNalZsyYAr732GjVr1uT9998H4NKlS7ZgApCQkMDrr79OtWrVaNasGQcPHmTNmjW0bNkym3Yh79E0jc+feZQvnq2JpmlprlO1hDePBvpgsij+2JPYJ+ZGVDzT1p60rbNo/wXiTJYMtxVyOZIBP+7h3/9uZ1v9QmSKTymKPDuPF/+3nRWlezHtdgL1Y+Mwo/j73Cq6/dWNISte4Hxk/urzJYTIfZrKB73PIiIi8Pb2Jjw8PN/1H8nIn3v/Y+T8g5TwcWXTmy0Y89dhftkRRuUAL8JjTVy4HcsXzzxK15ol0ny+1aro/OUWDl+IoHKAF/8Meyzd8CNEjjMnwJFFHN7xObMs11jj5orSNFw1PW/UfZPuFXvK51OIAiaz398P58xj+UTH6gF4uzpx4XYs3246w69J/Ufe71SZp+skDmf+dVf6p2oW7PuPwxcS52A5eimClUeu5HzRQqTH4Aw1nqHqi9v5rN0PLNGVpnZsHLHKwrhdExm0tCdXouUzKoRITcKIA7k46eleuyQAn6w4jlVB+6r+NChbmKfrlkSnwa7Qm5y+FpXqudHxZj5dmXitkDJFEvulfLHmBFaZ1VU4mqZB2eaU6bOUWU2nMDLKjLNVsfXmEZ5a0I6NoSsdXaEQIo+RMOJgveuXsv3bWa9jdPtKAAR4u9IiOHE+knlptI58s/E0VyPjKeXrxu8vNcDTaOD45UhWHHk4L0Ao8idd5c70fWE7f/jUo1J8AhHKzJBNI/ls/RuYrDKtvBAikYQRByvr50GTpIvn/e+x0pQq7GZ7rGe9xKCyYN8F4s13OrJeuB3LN5vOAPB2h4oU9XThf4+VAaR1RORBrj6Ue3IWv7SYTq9YKwCzw1bwwu+tuRwhnVuFEBJG8oTJPWowqXt1RrYJtlvePNiPYl5GbkYnsPpo4rl2q1XxyfLjxJut1C/jS9sq/gD0f6wMni4GTlyJ4p9DMs+DyHucK7RhdN+tTHGpgIfVyoGEG3RZ2IHv144kwSwTpglRkMlomjzus1UhTFt3Cl93Z1yd9FyNjMNkUWga/D3kMaqW8LatO3XNST5fc4LyRT1YOaIpep39yIXL4XG89Mte/DyMTOpeHV9359zeHSEAOL/3B0bvm8JBZz0AgUrPG1UH0rz2KzLiRoiHiIymeUg8XTcQJ73GzegELtyOtQWRgU3K2gURSDzN4+3qxKmrUXy49Kjd6ZrwGBN9Z+3i4PnbrDl2hS5fbiHkcsYzvB76L5xvNp7m6MUIuf6IyFaBtfvzU+8tfFSoHn4WC+c1C8OOfE3n2TX4YkE3Dh3+DWUxO7pMIUQukZaRfODf/25z/mYs/t5G/L1dKeppxEmfdo6cv+c8b/z5LwDdapXkk27VMFsVfX7Yxa6zNynqacTFSU/YzRjcnfV88WxNWlculup1tpy8zoCfdhNnSjzHX7qwG22r+tOtVkkeKeaZczsrCpzom6F8t2Y4P8ecISFFq0hRi5UaBm+q+JSnavGGVK7QCU/vkg6sVAiRVZn9/pYw8hBauO8/3vjzXyxWRevKxdCAVUev4Oli4I+XGuLv5cIrc/ex/cwNNA1eaFyGwS3K207brD9+lZd+2UuC2UqZIu5cvB1LvDkxlBh0Gl/2rmXrqyJEdomKuMDm/d+x5r/1bE64Qexdpxl1SlFZOVHPuzz1S7ehVuVncHGR3wdC5GUSRgq41UevMPjXfSQkhQhng46fXqhHg7KFATBZrIz7+yg/7zgHgIfRwIAmZShTxJ2R8w9isiQGmRm9amK2KNaHXOW3XWFsPXUDg05jRq9atKuafiA5fzOG0OvR1C3ti2tSvwAhMis+IZoDxxdw5PwWjtwO4Uj8TS7c9TFysyrauATQOfhpatfoh07v5JhihRDpkjAi2H76BgN/2kN0gpmZvWrRvlrqKyVvCLnKpytDOHIxwm75E9UC+OLZR+1OB5ktVl774yB/HbyIQacxvWdN22vGmSwcvRTB+uNXWX30CseT+qMU8XBmYJOyPNcgCHejIdX2r0bGsfroFbacvE4JH1eeqRtIBTkNJNJw+fIBdh/9nR2XdrAj/hpX9XdaTopbFB09K9Cxah/KBHcBnXSHEyIvkDAiALgaEUdEnJnyRT3SXcdqVSw/fJkpq0M4cy2aJ2uW4NPu1TGk0S/FbLEycv5BFh+4iF6n0SLYjzPXojl7I5qU05voNCjk5syN6AQACrk58WTNkrg46bAohcWiOHD+NnvDbnH3J7B2UCGerRvIE9UDcHNOHWBSUkphtioMOk1GYRQgymJm/6Gf+ev4b6yMvUhUilM6VUyKToWq8Fj5TpSq0AHNzdeBlQpRsEkYEVlmtlg5eyOGcn7uGX6xW6yKN+YfZOH+C3bLfdycaFyuCK0qF6X5I0XxcDGweP8FZm44Tej16HRfr0ZJbx6vWIzDF8NZd/wqlqRU4+asp11Sp9k6pQvx73/hbDpxjU0nr3PmWhQJZisJFitKgZ+nkVaVitK6cjEalSuC0aAjItbM5Yg4LoXHcuF2LBduJf4/zmShXpnCNA/2o2yR9PfVYlWE3YzBzVmPn4cRnU7CTl4UFxfB+r0zWRq6jK3mm1hSvJ9FzBZqK2dqepWhlE95ShSpRAn/mhgLVwBj+gFdCJE9JIyIHGWxKubuPEeC2UqwvyfBxTzx8zSm+cVutlhZdvgy+87dQtNAr2nodRrFfVxpXbkYxX1cbetejYhj/t7/+GPPec7diLEt1+s0W0i5F6NBh6ZhGwmUkUBfV+qW9sXP00gRdyOF3J25cCuWPeduciDsNpHxicNLDTqNYl4uBHi7UMjdGR9XJ3zcnDAa9ITHmgiPNXE71kSC2YLRoMfZoMNo0FHEw0igrxulfN0oWcgVJ72G2aowWxJbdOJMFmJNFuJNFpQCX3dniiTV4mbU21qNFAqLVWGyKEwWK1arws1owN1ZLy1CKdyIusTKvV+y6vwG/jWHY0rn0PhaLPhaFT6agUI6Fwo5uVPYyYvCrr4UditKEY/i+HmVwq9QWZw9AsDNF6RPihBZJmFE5GtKKfaF3WLhvgv8ffAiEXFmCrk58VgFP5pWKELNUj64OCV+6TvpdBy6EM6aY1dYc/QKF8PjbK/j4+aEv5cLJXxcKVHIlRI+rihg88lr7Aq9icmS8cffaNAlfvnn0Z8SvU7Dy8WAh4sBJ33isTDoE8Oe7XtY03DSabg46TEadLg46dGleFzTwGxRJFismJJamnzcnCjk5oyPmxMeRgOapqHTQKclhimTxYrJnLg+mpYUMEGv0+Gk1xLfF70OvaZhsiaua7Yq9DoNTxcnPF0MeLoYMBp06HWJ6+l0kGC2JoWzxFYvN2c97kYDHsbEdS1WhVUpLFaS/q9s/zfodDgZNJz0Opz1OiwqgVNXt3E0bBUnbh3jQsItLlpjiclidvO2WChisVBYaRTWnCisM+JlcMXLyR0vJ088jd64u/jg5uKLu1th3N2K4O5WDBe3IuhcfcDJFQyuiWEmO4Kj1QIWE1hNif+3mMCSAMpiv56mB71z4nb1TqA3Zl8NQmSShBHx0IgzWbgUHkcpX7dUs8reTSnF6WvROOkTWzJcnNIfyRMdb2bb6RucuBLJzegEbkTFcyM6AV93Z2oHFaJWqUJU9E/sTHs1Mp5L4bFcDo/ndmwCt2NMRMSaiDNZ8HZ1wtvNGW9XJ5wNusTTR2Yr8WYLVyLiOX8zhrCbMVy4HYtVJfZv0es0DDodrs56XJx0uDrpsSoSa4hKsLXIpEfTSNXXRmSGQtPH4Ga4irfhGh76G7g53cbJEAH6KCz6GOINCcTozdw2WDE/4Be3q9WKq1K4WhUuSuGiwEmBk1JJ/0+ceVIH6JVCB2gpbpD8JisS28eUbYk1eammkdwGaHuuUugh8aYUBsCgFAYFOnQYND0aOtt/oEOPDjTQoYGmoSll2y5ooOnQktbVND16nSHppk8qNmldZcViScBqTcBiNaEwJ35YFWhY0TQdTjpnnHROGPTO6HUGdJoBDT2aZkBTVjSsoKwoZUEpE8pqwmo1AwonnRM6nRN6nRMGgxGD3hWDkwtOTm6Js3gqMygLymrGbI7HZInDbI7HarUkbkunR6/TY9A542RwwWAw4mRwRafpQFmTarUk7oM5Dos5HmvSRR1tx1fTYdA5Y9Ab0OuM6DQNpSxgNYPV9s6gJb1ZOk2HTtPQ0KFpOtt7q6ElvZ4+aR0daDp0mj7pDwAtcf2kxzRNSwyjypq4HZX8zis0Et9bnd6AXueETu+cGFAtJlTSzbYPuqRPms4AegPokgJr/ZfBt8wDfebvJmFEiHwsLql1ACDpuwFDUoBxShpFEmeyEhGXGIoi4syYLYmtDwlJp3GSKQVmq5U4k5U4k4U4kwWrSvE1p5StJcNJr0MpRXisiVsxCdyKMRETb0YBVpXY2Vmv01Ksr6EUWJTCalVJp6CsmJJaWixJnYud9IktNmarIjLOTGScicg4MyaLFbPlTuuGsyExmLk46THoNWITLETFm4mONxNvtia1oCSGOb0usbUmeZnVqkhIOo2VYE7cttn6IK1aCnSx6J1u46G/jpvTDYz6WzgZItDpY9D0cVh1cVj1Jsw6M2adhXidlXgNlDQ+iDxOlxR+DUn/1yuYWPUtmtV7Plu3k9nv74yHKgghHMIl6Qs5I67Oelyd9RTzcsmlqvInq1UlhiWlEv/oTQpPFktiWDFblV0rk0LZThfFJiT26dFpdwKQRuIpIrMlMUApkoKiXkOv02G2WIiIiyMiPorwuEjiTBEkJESQYIrEZI4CzQSYQTNjURasyooFS1KNFludVmXFioZFaVitGmarhqbTgy6xBQGdHk3nnPiXvpbYqmFVycHOislsIdZsIs4Uj8kcj6YS0GsmNM2EjgQ0ZUmsAzNKmRP7JSkrSlmxqqTWENtNAUktFlgTa7Nakuq1JP5dbgu4Gko5oTQDShlQGJJODWlJj1uwWhOwYkIpE5pmTbpZSG5KUGiJN6WhlA6ldFjRo5RKXBcLJD8HC2gWlJaifciWBvWQ9HzbfmiJ+4JmRaW4paQATSW2NZD0f2V7JPEzgqbSeK59e9adT1TSvzSVxqNJ62jJr5veJzl7WZNa1FK2/t3UvNN/Qg6TMCKEeKjpdBq63PoNL3KdSmpVS24VTD5NarYoWx8iJ73O1gneFk6TnmNJ6gOlSHnqU6XoPJ64PPk7WyMxzCb3s0owJ/az0mnY+mI5G3SJN1trY2LrpCVFjfFJdVqUwqjXYUhqPdQAS1JINlsT+wHpdCopSllJMCUG5ThzYmunNSk8WhVYrBYU1qSAmNgqaLUoLGhJ+2vFYrGSYLVitSYFMhIDHlipWa5G7r1xd5EwIoQQIt/StMRWKYOee7YmirxLpikUQgghhENJGBFCCCGEQ0kYEUIIIYRDSRgRQgghhENJGBFCCCGEQ0kYEUIIIYRDSRgRQgghhENJGBFCCCGEQ0kYEUIIIYRDSRgRQgghhENJGBFCCCGEQ0kYEUIIIYRDSRgRQgghhEPli6v2qqRrOUdERDi4EiGEEEJkVvL3dvL3eHryRRiJjIwEIDAw0MGVCCGEECKrIiMj8fb2TvdxTd0rruQBVquVixcv4unpiaZp2fa6ERERBAYGcv78eby8vLLtdR9WcryyRo5X1sjxyjw5VlkjxytrsvN4KaWIjIykePHi6HTp9wzJFy0jOp2OkiVL5tjre3l5yQc0C+R4ZY0cr6yR45V5cqyyRo5X1mTX8cqoRSSZdGAVQgghhENJGBFCCCGEQxXoMGI0GhkzZgxGo9HRpeQLcryyRo5X1sjxyjw5VlkjxytrHHG88kUHViGEEEI8vAp0y4gQQgghHE/CiBBCCCEcSsKIEEIIIRxKwogQQgghHErCiBBCCCEcqkCHkS+//JLSpUvj4uJC/fr12bVrl6NLcriJEydSt25dPD09KVq0KF27diUkJMRunbi4OAYPHkzhwoXx8PCgW7duXLlyxUEV5y0ff/wxmqYxYsQI2zI5XvYuXLjAc889R+HChXF1daVatWrs2bPH9rhSivfff5+AgABcXV1p1aoVJ0+edGDFjmOxWHjvvfcoU6YMrq6ulCtXjg8//NDuomMF+Xht2rSJTp06Ubx4cTRNY/HixXaPZ+bY3Lx5k969e+Pl5YWPjw/9+/cnKioqF/cid2R0rEwmE6NGjaJatWq4u7tTvHhx+vTpw8WLF+1eIyePVYENI7///juvvfYaY8aMYd++fdSoUYO2bdty9epVR5fmUBs3bmTw4MHs2LGD1atXYzKZaNOmDdHR0bZ1Xn31Vf7++2/mz5/Pxo0buXjxIk899ZQDq84bdu/ezTfffEP16tXtlsvxuuPWrVs0btwYJycnli9fztGjR5kyZQqFChWyrTNp0iSmTZvG119/zc6dO3F3d6dt27bExcU5sHLH+OSTT/jqq6+YMWMGx44d45NPPmHSpElMnz7dtk5BPl7R0dHUqFGDL7/8Ms3HM3NsevfuzZEjR1i9ejVLly5l06ZNvPjii7m1C7kmo2MVExPDvn37eO+999i3bx8LFy4kJCSEzp07262Xo8dKFVD16tVTgwcPtt23WCyqePHiauLEiQ6sKu+5evWqAtTGjRuVUkrdvn1bOTk5qfnz59vWOXbsmALU9u3bHVWmw0VGRqoKFSqo1atXq2bNmqnhw4crpeR43W3UqFHqscceS/dxq9Wq/P391aeffmpbdvv2bWU0GtVvv/2WGyXmKU888YR64YUX7JY99dRTqnfv3kopOV4pAWrRokW2+5k5NkePHlWA2r17t22d5cuXK03T1IULF3Kt9tx297FKy65duxSgzp07p5TK+WNVIFtGEhIS2Lt3L61atbIt0+l0tGrViu3btzuwsrwnPDwcAF9fXwD27t2LyWSyO3YVK1akVKlSBfrYDR48mCeeeMLuuIAcr7v99ddf1KlThx49elC0aFFq1qzJd999Z3s8NDSUy5cv2x0vb29v6tevXyCPV6NGjVi7di0nTpwA4ODBg2zZsoX27dsDcrwykpljs337dnx8fKhTp45tnVatWqHT6di5c2eu15yXhIeHo2kaPj4+QM4fq3xx1d7sdv36dSwWC8WKFbNbXqxYMY4fP+6gqvIeq9XKiBEjaNy4MVWrVgXg8uXLODs72z6gyYoVK8bly5cdUKXjzZs3j3379rF79+5Uj8nxsnfmzBm++uorXnvtNd5++212797NsGHDcHZ2pm/fvrZjktbPZkE8Xm+99RYRERFUrFgRvV6PxWJhwoQJ9O7dG0COVwYyc2wuX75M0aJF7R43GAz4+voW6OMXFxfHqFGj6Nmzp+2qvTl9rApkGBGZM3jwYA4fPsyWLVscXUqedf78eYYPH87q1atxcXFxdDl5ntVqpU6dOnz00UcA1KxZk8OHD/P111/Tt29fB1eX9/zxxx/MnTuXX3/9lSpVqnDgwAFGjBhB8eLF5XiJHGEymXj66adRSvHVV1/l2nYL5GmaIkWKoNfrU41ouHLlCv7+/g6qKm8ZMmQIS5cuZf369ZQsWdK23N/fn4SEBG7fvm23fkE9dnv37uXq1avUqlULg8GAwWBg48aNTJs2DYPBQLFixeR4pRAQEEDlypXtllWqVImwsDAA2zGRn81Eb7zxBm+99RbPPvss1apV4/nnn+fVV19l4sSJgByvjGTm2Pj7+6catGA2m7l582aBPH7JQeTcuXOsXr3a1ioCOX+sCmQYcXZ2pnbt2qxdu9a2zGq1snbtWho2bOjAyhxPKcWQIUNYtGgR69ato0yZMnaP165dGycnJ7tjFxISQlhYWIE8di1btuTQoUMcOHDAdqtTpw69e/e2/VuO1x2NGzdONVT8xIkTBAUFAVCmTBn8/f3tjldERAQ7d+4skMcrJiYGnc7+17Rer8dqtQJyvDKSmWPTsGFDbt++zd69e23rrFu3DqvVSv369XO9ZkdKDiInT55kzZo1FC5c2O7xHD9WD9wFNp+aN2+eMhqNas6cOero0aPqxRdfVD4+Pury5cuOLs2hBg0apLy9vdWGDRvUpUuXbLeYmBjbOi+//LIqVaqUWrdundqzZ49q2LChatiwoQOrzltSjqZRSo5XSrt27VIGg0FNmDBBnTx5Us2dO1e5ubmpX375xbbOxx9/rHx8fNSSJUvUv//+q7p06aLKlCmjYmNjHVi5Y/Tt21eVKFFCLV26VIWGhqqFCxeqIkWKqDfffNO2TkE+XpGRkWr//v1q//79ClCfffaZ2r9/v20ESGaOTbt27VTNmjXVzp071ZYtW1SFChVUz549HbVLOSajY5WQkKA6d+6sSpYsqQ4cOGD3uz8+Pt72Gjl5rApsGFFKqenTp6tSpUopZ2dnVa9ePbVjxw5Hl+RwQJq32bNn29aJjY1Vr7zyiipUqJByc3NTTz75pLp06ZLjis5j7g4jcrzs/f3336pq1arKaDSqihUrqm+//dbucavVqt577z1VrFgxZTQaVcuWLVVISIiDqnWsiIgINXz4cFWqVCnl4uKiypYtq9555x27L4iCfLzWr1+f5u+rvn37KqUyd2xu3LihevbsqTw8PJSXl5f63//+pyIjIx2wNzkro2MVGhqa7u/+9evX214jJ4+VplSKqfyEEEIIIXJZgewzIoQQQoi8Q8KIEEIIIRxKwogQQgghHErCiBBCCCEcSsKIEEIIIRxKwogQQgghHErCiBBCCCEcSsKIEEIIIRxKwogQQgghHErCiBBCCCEcSsKIEEIIIRzq/7/LVofppX8QAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outcome = torch.cat([test_data.pos_edge_label, test_data.neg_edge_label]).cpu().detach().numpy()\n",
        "mean_pred = outcome.mean()"
      ],
      "metadata": {
        "id": "LVopQ76V9ni0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outcome.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xaZnqvsCuD6",
        "outputId": "11405499-99cc-449a-cbed-c9ad7f03dc85"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32269,)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_tensor = torch.tensor(np.array([mean_pred] * 32269), dtype=torch.float32)\n",
        "outcome_tensor = torch.tensor(outcome, dtype=torch.float32)\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(pred_tensor, outcome_tensor)\n",
        "print(r2)"
      ],
      "metadata": {
        "id": "NgKNmXav-bdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c62a6f3-2258-4dc0-8636-b5059cd77f57"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.)\n"
          ]
        }
      ]
    }
  ]
}